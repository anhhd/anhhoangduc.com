

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="vi" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="vi" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>5. Bagging, RandomForest và Boosting &mdash; Tài liệu Phân tích dữ liệu với R 2019</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'./',
              VERSION:'2019',
              LANGUAGE:'vi',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="_static/copybutton.js"></script>
        <script type="text/javascript" src="_static/translations.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Tìm Kiếm" href="search.html" />
    <link rel="next" title="6. Xây dựng mô hình với H2O" href="p03-07-xay-dung-mo-hinh-voi-h2o.html" />
    <link rel="prev" title="4. Cây quyết định" href="p03-04-decision-tree.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Phân tích dữ liệu với R
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Giới thiệu</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p01-01-gioi-thieu.html">Khoa học dữ liệu và nghề phân tích dữ liệu</a></li>
</ul>
<p class="caption"><span class="caption-text">Phân tích khám phá dữ liệu</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p02-03-bien-doi-du-lieu-dplyr.html">1. Ngữ pháp của biến đổi dữ liệu với DPLYR</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-04-phan-ra-va-xoay-chieu-du-lieu.html">2. Phân rã và xoay chiều dữ liệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-05-cac-chi-so-thong-ke.html">3. Các chỉ số thống kê mô tả cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-06-lap-trinh-ham.html">4. Lập trình hàm</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-07-lap-trinh-ham-voi-purrr.html">5. Lập trình chức năng hàm với purrr</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-08-bien-doi-du-lieu-text.html">6. Biến đổi dữ liệu text</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-11-quan-ly-nhieu-mo-hinh.html">7. Quản lý kết quả phân tích từ nhiều mô hình</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-15-thong-ke-co-ban.html">8. Xác suất và phân phối thống kê cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-16-power-analysis.html">9. Power analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-20-sampling-methods.html">10. Phương pháp ước lượng lấy mẫu</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-50-datatable.html">11. Biến đổi dữ liệu với <code class="docutils literal notranslate"><span class="pre">data.table</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-60-thu-thap-du-lieu-tu-website.html">12. Thu thập dữ liệu từ website</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-99-meo-trong-r.html">13. Các mẹo trong R</a></li>
</ul>
<p class="caption"><span class="caption-text">Supervised learning</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="p03-01-nguyen-ly-du-bao.html">1. Các nguyên lý dự báo</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-02-mo-hinh-ols.html">2. Mô hình OLS</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-03-logistic-regression.html">3. Mô hình hồi quy logistic</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-04-decision-tree.html">4. Cây quyết định</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">5. Bagging, RandomForest và Boosting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#bagging">5.1. Bagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="#random-forests">5.2. Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="#boosting">5.3. Boosting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="p03-07-xay-dung-mo-hinh-voi-h2o.html">6. Xây dựng mô hình với H2O</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-08-svm.html">7. Support Vector Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-09-feature-engineering.html">8. Feature Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-15-regularization.html">9. Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-17-nonlinear.html">10. Mô hình phi tuyến tính</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-30-credit-scoring.html">11. Credit Scoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-35-caret.html">12. Xây dựng mô hình dự báo với caret</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-65-chat-luong-mo-hinh.html">13. Chất lượng mô hình</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-70-tidymodels.html">14. Tidymodels</a></li>
</ul>
<p class="caption"><span class="caption-text">Unsupervised learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p04-01-unsupervised-learning.html">1. Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-02-kmeans.html">2. k-means</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-03-hierarchical-clustering.html">3. Hierachical clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-04-basket-analysis.html">4. Phân tích giỏ hàng</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-05-pca.html">5. Principal component analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-06-factor-analysis.html">6. Phân tích nhân tố ẩn (factor analysis)</a></li>
</ul>
<p class="caption"><span class="caption-text">Chuỗi thời gian</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p05-01-chuoi-thoi-gian.html">1. Giới thiệu về chuỗi thời gian</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-02-arima.html">2. Mô hình ARIMA</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-03-phan-tich-chuoi-thoi-gian-voi-tidyquant.html">3. Phân tích chuỗi thời gian với tidyquant và timetk</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-06-du-bao-ts-voi-prophet.html">4. Dự báo chuỗi thời gian với prophet</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-07-du-bao-ts-voi-timetk.html">5. Dự báo chuỗi thời gian với timetk</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-08-abnomaly-detection.html">6. Abnomaly detection trong times series</a></li>
</ul>
<p class="caption"><span class="caption-text">Ngôn ngữ tự nghiên</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p06-01-nlp-co-ban.html">1. Xử lý ngôn ngữ tự nhiên cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p06-04-text-classification.html">2. Phân loại text</a></li>
<li class="toctree-l1"><a class="reference internal" href="p06-07-nlp-api.html">3. Sử dụng API từ các dịch vụ đám mây</a></li>
<li class="toctree-l1"><a class="reference internal" href="p06-10-ocr-tesseract.html">4. OCR với <code class="docutils literal notranslate"><span class="pre">tesseract</span></code></a></li>
</ul>
<p class="caption"><span class="caption-text">Các phương pháp khác</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p07-01-survival-analysis.html">1. Survival analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-02-causal-impact.html">2. Causal Impact</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-03-collaborative-filtering.html">3. Collaborative Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-07-spatial-data.html">4. Spatial data</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-10-shiny.html">5. Shiny apps</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p09-01-gioi-thieu-deep-learning.html">1. Giới thiệu cơ bản về Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="p09-02-co-ban-kien-thuc-toan.html">2. Kiến thức cơ bản toán học cho deep learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="p09-03-mo-hinh-deep-learning-co-ban.html">3. Mô hình deep learning cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p09-04-convolution-neural-network.html">4. Convolution neural networks</a></li>
</ul>
<p class="caption"><span class="caption-text">Cloud Computing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p10-01-cai-dat-rstudio-server-tren-amazon.html">1. Cài đặt server RStudio trên Amazon</a></li>
<li class="toctree-l1"><a class="reference internal" href="p10-03-web-service-azure.html">2. Xây dựng web service với Azure</a></li>
<li class="toctree-l1"><a class="reference internal" href="p10-09-apis-voi-plumber.html">3. API với Plumber</a></li>
</ul>
<p class="caption"><span class="caption-text">Kiến thức bổ trợ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p11-01-git.html">1. Sử dụng GIT</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-02-cmd.html">2. CMD và Bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-03-docker.html">3. Sử dụng docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-04-apis.html">4. API</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-05-html-css.html">5. Cơ bản về HTML và CSS</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-09-other.html">6. Các tricks khác</a></li>
</ul>
<p class="caption"><span class="caption-text">Case studies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p13-01-casestudy-truc-quan-hoa.html">1. Trực quan hóa dữ liệu</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Phân tích dữ liệu với R</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>5. Bagging, RandomForest và Boosting</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/p03-05-bagging-boosting.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="bagging-randomforest-va-boosting">
<h1>5. Bagging, RandomForest và Boosting<a class="headerlink" href="#bagging-randomforest-va-boosting" title="Permalink to this headline">¶</a></h1>
<div class="section" id="bagging">
<h2>5.1. Bagging<a class="headerlink" href="#bagging" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<center><p><img alt="image0" src="./Images/tree-2.png" /></p>
</center><hr class="docutils" />
<p>Mô hình cây quyết định như đã đề cập, sẽ gặp phải vấn đề
<code class="docutils literal notranslate"><span class="pre">high</span> <span class="pre">variance</span></code>. Nghĩa là nếu chúng ta chia ngẫu nhiên tập dữ liệu
training làm 2 tập dữ liệu con, và sau đó xây dựng mô hình trên 2 tập dữ
liệu con đó, kết quả nhận được sẽ có thể khá khác nhau.
<code class="docutils literal notranslate"><span class="pre">Boostrap</span> <span class="pre">aggregation</span></code> hay <code class="docutils literal notranslate"><span class="pre">bagging</span></code> sẽ có thể làm giảm variance,
đây là một phương pháp rất hiệu quả và phổ biến khi chúng ta sử dụng các
phương pháp liên quan đến cây quyết định.</p>
<p>Giả sử, có tập hợp n quan sát độc lập Z1,…, Zn, mỗi quan sát với
variance σ^2, variance của giá trị trung bình các quan sát Z là
σ^2/n.&nbsp;Nói cách khác, trung bình tập hợp các quan sát sẽ làm giảm
variance. Vì thế cách tự nhiên nhất để làm giảm variance và tăng độ
chính xác của dự báo là lấy thật nhiều các dữ liệu training khác nhau,
rồi xây dựng các mô hình dự báo sử dụng các tập dữ liệu training đó, sau
đó lấy trung bình các kết quả dự báo. Nói cách khác, chúng ta sẽ tính
toán fˆ1(x), fˆ2(x), . . . , fˆB(x) sử dụng B tập dữ liệu training khác
nhau, sau đó lấy trung bình để nhận được một mô hình đơn với variance
thấp như sau:</p>
<div class="math notranslate">
\[\widehat{f}_{avg}(x) = \frac{1}{B}\sum_{b=1}^{B}\widehat{f}^{b}(x)\]</div>
<p>Tuy nhiên, điều đó là không thực tế vì chúng ta không thể có nhiều dữ
liệu training khác nhau, dữ liệu là hữu hạn. Vì vậy, chúng ta sẽ sử dụng
<code class="docutils literal notranslate"><span class="pre">boostrap</span></code>, tức phương pháp lấy mẫu ngẫu nhiên có hoàn lại từ tập dữ
liệu training duy nhất của chúng ta. Theo đó, chúng ta sẽ tạo ra B
boostrapped dữ liệu training khác nhau để có được các giá trị dự báo
khác nhau, và sau đó sẽ lấy trung bình tất cả các kết quả dự báo, thu
được kết quả cuối cùng:</p>
<div class="math notranslate">
\[\widehat{f}_{bag}(x) = \frac{1}{B}\sum_{b=1}^{B}\widehat{f^{*}}^{b}(x)\]</div>
<p>Đây gọi là <code class="docutils literal notranslate"><span class="pre">bagging</span></code>. Bagging có thể cải thiện chất lượng dự báo cho
rất nhiều các mô hình hồi quy, đặc biệt hiệu quả đối với mô hình cây
quyết định. Để áp dụng bagging với regression trees, chúng ta đơn giản
chỉ cần xây dựng B regression trees sử dụng B boostrapped dữ liệu
training, sau đó lấy trung bình các kết quả dự báo. Những cây quyết định
này được xây dựng rất sâu (nhiều tầng) và không được “tỉa”. Vì thế mỗi
cây quyết định trên sẽ có variance cao, nhưng bias thấp. Lấy trung bình
kết quả B cây quyết định này sẽ làm giảm variance. Bagging có thể cải
thiện chất lượng dự báo một cách đáng kể khi kết hợp hàng trăm hoặc thậm
chí hàng nghìn cây quyết định lại với nhau.</p>
<p>Cho đến thời điểm hiện tại, chúng ta đã mô tả phương pháp bagging đối
với regression trees, tức dự báo biến đầu ra là biến liên tục. Vậy
phương pháp bagging có thể sử dụng với bài toán mà biến đầu ra là biến
rời rạc không? Trong trường hợp này, giả sử khi chúng ta muốn phân loại
một quan sát mới, chúng ta có thể dự báo được quan sát mới trên thuộc
class nào trong B cây quyết định khác nhau, rồi sau đó, lấy
<code class="docutils literal notranslate"><span class="pre">majority</span> <span class="pre">vote</span></code> - tức là, quan sát mới trên sẽ rơi vào class mà tần
suất xuất hiện của nó nhiều nhất trong B kết quả dự báo khác nhau.</p>
<p>Trong phương pháp bagging, tham số về số lượng cây quyết định B nói trên
mà càng lớn thì cũng không thể dẫn đến overfitting. Trong thực tế, chúng
ta sẽ chọn số lượng cây quyết định đủ lớn để sao cho sai số đủ nhỏ.</p>
<p><strong>Out-of-Bag Error Estimation</strong></p>
<p>Có một cách khá đơn giản để ước lượng sai số dự báo (test error) của mô
hình bagging mà không cần dùng cross-validation hoặc tập dữ liệu
validation. Nhắc lại key của phương pháp bagging là việc các cây quyết
định sẽ được xây dựng nhiều lần sử dụng những tập dữ liệu bootstrapped
khác nhau. Mỗi một cây quyết định được xây đều sử dụng khoảng 2/3 số
quan sát, còn 1/3 quan sát còn lại không được sử dụng trong quá trình
xây dựng mô hình sẽ được gọi là những quan sát <code class="docutils literal notranslate"><span class="pre">out-of-bag</span></code> (OOB).
Chúng ta có thể dự báo kết quả cho quan sát thứ i sử dụng từng cây quyết
định mà các quan sát là OOB. Điều này sẽ mang lại khoảng B/3 giá trị dự
báo cho quan sát thứ i này. Để dự báo giá trị cuối cùng của quan sát đó,
chúng ta sẽ lấy trung bình các kết quả dự báo (đối với bài toán hồi quy
- regression) hoặc lấy theo số đông - majority vote (đối với bài toán
phân loại - classification). Đó chính là kết quả dự báo OOB (OOB
prediction) cho quan sát i. OOB prediction có thể sử dụng cho từng n
quan sát, và có thể tính toán được OOB MSE (đối với bài toán hồi quy)
hoặc classification error (đối với bài toán phân loại). Cách sử dụng OOB
để ước lượng sai số dự báo (test error) sẽ thuận tiện hơn so với cách
cross-validation khi sử dụng bagging đối với tập dữ liệu lớn.</p>
<p><strong>Variable Importance Measures</strong></p>
<p>Như vừa tìm hiểu, <code class="docutils literal notranslate"><span class="pre">bagging</span></code> sẽ cải thiện được độ chính xác của dự báo
so với mô hình cây quyết định đơn lẻ. Tuy nhiên, bagging lại rất khó để
giải thích kết quả mô hình do việc tổng hợp rất nhiều cây quyết định
khác nhau.</p>
<p>Mặc dù đối với bagging rất khó để giải thích kết quả mô hình, nhưng
chúng ta vẫn có thể xem được thống kê tổng quát về mức độ quan trọng của
các biến đầu vào trong mô hình bằng việc sử dụng RSS (đối với bagging
regression trees) hoặc chỉ số Gini (đối với bagging classification
trees).</p>
</div>
<div class="section" id="random-forests">
<h2>5.2. Random Forests<a class="headerlink" href="#random-forests" title="Permalink to this headline">¶</a></h2>
<p>Cũng giống như <code class="docutils literal notranslate"><span class="pre">bagging</span></code>, <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code> cũng xây dựng một tập hợp
các cây quyết định sử dụng các tập dữ liệu con được chia theo phương
pháp boostrap (lấy mẫu ngẫu nhiên có hoàn lại) từ tập dữ liệu training
ban đầu. Tuy nhiên, với phương pháp <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code> thì những tập dữ
liệu con đó sẽ không bao gồm tất cả các biến đầu vào (p - tổng số lượng
biến đầu vào) trong tập dữ liệu training ban đầu như <code class="docutils literal notranslate"><span class="pre">bagging</span></code> mà chỉ
bao gồm m biến nhất định (thông thường m ~ sqrt(p)).</p>
<p>Đối với <code class="docutils literal notranslate"><span class="pre">bagging</span></code> các cây quyết định có thể tương quan chặt chẽ với
nhau (<code class="docutils literal notranslate"><span class="pre">highly</span> <span class="pre">correlated</span></code>) do các cây đều lấy cùng một số lượng là tất
cả các biến đầu vào trong tập dữ liệu training ban đầu. Điều đó sẽ dẫn
đến việc variance sẽ cao. Trong khi đó, <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code> có thể khắc
phục được vấn đề trên khi mỗi cây quyết định được xây dựng chỉ lấy ngẫu
nhiên m biến đầu vào ngẫu nhiên. Quá trình đó được gọi là
<code class="docutils literal notranslate"><span class="pre">decorrelating</span></code>. Quá trình này sẽ giúp kết quả dự báo đáng tin cậy
hơn.</p>
<p>Như vậy, điểm khác biệt quan trọng nhất giữa <code class="docutils literal notranslate"><span class="pre">bagging</span></code> và
<code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code> là việc chọn số lượng biến đầu vào:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">bagging</span></code> lấy tất cả các biến đầu vào (p)</li>
<li><code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code> lấy m biến nhất định (m ~ sqrt(p))</li>
</ul>
<p>Vì thế, nếu xây dựng mô hình <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code> với số lượng biến đầu
vào m = p (tức lấy tất cả các biến đầu vào) thì mô hình trở thành
<code class="docutils literal notranslate"><span class="pre">bagging</span></code>. Do đó, có thể nói bagging là một trường hợp đặc biệt của
random forests.</p>
<p>Thuật toán của <code class="docutils literal notranslate"><span class="pre">Random</span> <span class="pre">Forest</span></code> sẽ bao gồm việc lấy mẫu và chọn biến để
xây dựng một số lượng lớn các cây quyết định khác nhau. Kết quả dự báo
cuối cùng của một quan sát sẽ lấy trung bình các kết quả dự báo của các
cây quyết định (đối với bài toán hồi quy - regression) hoặc lấy majority
vote từ các kết quả dự báo từ các cây quyết định để xác định quan sát đó
thuộc class nào (đối với bài toán phân loại - classification).</p>
<p>Giả định rằng N là số lượng quan sát của tập dữ liệu training và p là số
lượng biến đầu vào. Thuật toán sẽ diễn ra theo các bước như sau:</p>
<ul class="simple">
<li><strong>Bước 1</strong>: Xây dựng số lượng lớn các cây quyết định bằng việc lấy
mẫu ngẫu nhiên có hoàn lại N quan sát từ tập dữ liệu training</li>
<li><strong>Bước 2</strong>: Với mỗi cây quyết định lựa chọn m &lt; p biến nhất định.
Những biến này được cân nhắc lựa chọn để phân nhánh, với mỗi cây
quyết định thì đều có số lượng biến là m.</li>
<li><strong>Bước 3</strong>: Xây dựng các cây (không thực hiện tỉa cây)</li>
<li><strong>Bước 4</strong>: Dự báo các quan sát mới bằng việc lấy trung bình các kết
quả dự báo của các cây quyết định khác nhau đã được xây dựng (đối với
bài toán hồi quy), hoặc lấy theo kết quả số đông của các cây quyết
định khác nhau đã được xây dựng (đối với bài toán phân loại).</li>
</ul>
<p>Out-of-bag (OOB) error estimate được tính toán bằng việc phân loại quan
sát mới mà không có trong tập dữ liệu training khi xây dựng cây quyết
định. Việc này sẽ hữu ích khi mà chúng ta không có dữ liệu validation.</p>
<p>Trong <code class="docutils literal notranslate"><span class="pre">R</span></code> để xây dựng mô hình random forests chúng ta có thể sử dụng
hàm <code class="docutils literal notranslate"><span class="pre">randomForest()</span></code> trong package <strong>randomForest</strong>. Số lượng cây mặc
định là 500, số lượng biến tại mỗi cây mặc định là sqrt(tổng số biến),
và kích thước nhỏ nhất của cây mặc định là 1.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kn">library</span><span class="p">(</span>ISLR<span class="p">)</span>
<span class="kn">library</span><span class="p">(</span>randomForest<span class="p">)</span> <span class="c1"># Package sử dụng cho Random Forests</span>
<span class="kp">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span>

<span class="c1"># Data</span>
data<span class="p">(</span><span class="s">&quot;Default&quot;</span><span class="p">)</span>

<span class="c1"># Chia dữ liệu thành 2 tập: train/test</span>
<span class="kp">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span>
train <span class="o">&lt;-</span> <span class="kp">sample</span><span class="p">(</span><span class="kp">nrow</span><span class="p">(</span>Default<span class="p">),</span> <span class="m">0.7</span><span class="o">*</span><span class="kp">nrow</span><span class="p">(</span>Default<span class="p">))</span>
df.train <span class="o">&lt;-</span> Default<span class="p">[</span>train<span class="p">,]</span>
df.validate <span class="o">&lt;-</span> Default<span class="p">[</span><span class="o">-</span>train<span class="p">,]</span>

<span class="c1"># Biến đầu ra của dữ liệu huấn luyện</span>
<span class="kp">table</span><span class="p">(</span>df.train<span class="o">$</span>default<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##</span>
<span class="c1">##   No  Yes</span>
<span class="c1">## 6765  235</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Biến đầu ra của dữ liệu kiểm tra</span>
<span class="kp">table</span><span class="p">(</span>df.validate<span class="o">$</span>default<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##</span>
<span class="c1">##   No  Yes</span>
<span class="c1">## 2902   98</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Xây dựng mô hình trên tập training</span>
fit_rf <span class="o">&lt;-</span> randomForest<span class="p">(</span>default <span class="o">~</span> <span class="m">.</span><span class="p">,</span>
                       data <span class="o">=</span> df.train<span class="p">,</span>
                       <span class="c1"># na.action = na.roughfix, # Xử lý giá trị missing (nếu có)</span>
                       importance <span class="o">=</span> <span class="bp">T</span>
                       <span class="p">)</span>

fit_rf
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##</span>
<span class="c1">## Call:</span>
<span class="c1">##  randomForest(formula = default ~ ., data = df.train, importance = T)</span>
<span class="c1">##                Type of random forest: classification</span>
<span class="c1">##                      Number of trees: 500</span>
<span class="c1">## No. of variables tried at each split: 1</span>
<span class="c1">##</span>
<span class="c1">##         OOB estimate of  error rate: 2.66%</span>
<span class="c1">## Confusion matrix:</span>
<span class="c1">##       No Yes class.error</span>
<span class="c1">## No  6736  29  0.00428677</span>
<span class="c1">## Yes  157  78  0.66808511</span>
</pre></div>
</div>
</div>
<div class="section" id="boosting">
<h2>5.3. Boosting<a class="headerlink" href="#boosting" title="Permalink to this headline">¶</a></h2>
<p>Bây giờ chúng ta sẽ cùng thảo luận về <code class="docutils literal notranslate"><span class="pre">boosting</span></code>, một phương pháp khác
để cải thiện chất lượng dự báo từ việc sử dụng cây quyết định. Giống như
các phương pháp trước, boosting có thể áp dụng được đối với cả 2 bài
toán: Hồi quy (regression) và phân loại (classification).</p>
<p>Nhắc lại một chút, boosting và random forests sử dụng phương pháp
boostrap (lấy mẫu ngẫu nhiên có hoàn lại) để tạo các tập dữ liệu con từ
dữ liệu training ban đầu, sau đó xây dựng các cây quyết định đối với
từng tập dữ liệu con đó (các cây quyết định được xây dựng độc lập với
nhau). Cuối cùng, sẽ tổng hợp lại các cây quyết định để ra được kết quả
dự báo cuối cùng bằng cách lấy trung bình các kết quả dự báo của các cây
quyết định (đối với bài toán hồi quy), hoặc lấy theo số đông các kết quả
dự báo của các cây quyết định (đối với bài toán phân loại).</p>
<p>Boosting cũng hoạt động theo cách tương tự, nhưng khác ở chỗ là việc xây
dựng các cây quyết định từ những tập dữ liệu con khác nhau không phải là
độc lập hoàn toàn với nhau như bagging hay random forests. Thay vào đó,
boosting xây dựng các cây quyết định một cách có trình tự
(<code class="docutils literal notranslate"><span class="pre">sequentially</span></code>): Mỗi cây kế tiếp được xây dựng bằng cách sử dụng kết
quả từ những cây trước đó. Boosting tập trung nhiều hơn vào những quan
sát bị dự báo sai từ những cây trước để góp phần cải thiện kết quả dự
báo cuối cùng. Boosting không dùng boostrap để chia tập dữ liệu training
ban đầu, mà thay vào đó là việc dùng các phiên bản đã được modified từ
tập dữ liệu train ban đầu để xây dựng các cây quyết định.</p>
<p>Chúng ta sẽ cùng xem xét bài toán hồi quy. Giống như bagging và
randomforests, boosting kết hợp nhiều cây quyết định lại với nhau: f1,…,
fB.</p>
<p>Thuật toán boosting đối với bài toán hồi quy:</p>
<ul class="simple">
<li><strong>Bước 1</strong>: Đặt fˆ(x) = 0 và ri = yi với mọi i trên tập dữ liệu
training</li>
<li><strong>Bước 2</strong>: Với b = 1,2.., B, lặp lại:<ul>
<li>Xây dựng một cây fˆb với d splits (d+1 terminal nodes) với dữ liệu
training (X,r).</li>
<li>Update fˆ bằng việc adding in a shrunken version of the new tree,
và update residuals:</li>
</ul>
</li>
</ul>
<div class="math notranslate">
\[\widehat{f}(x) = \widehat{f}(x) + λ\widehat{f}^{b}(x)\]</div>
<div class="math notranslate">
\[r_i = r_i - λ\widehat{f}^{b}(x_i)\]</div>
<ul class="simple">
<li><strong>Bước 3</strong>: Kết quả của boosted model:</li>
</ul>
<div class="math notranslate">
\[\widehat{f}(x) = \sum_{b=1}^{P}λ\widehat{f}^{b}(x)\]</div>
<p>Thay vì việc xây dựng các cây quyết định đơn lẻ với kích thước lớn có
thể dẫn đến vấn đề overfitting, phương pháp boosting sẽ “học” chậm
(<code class="docutils literal notranslate"><span class="pre">learn</span> <span class="pre">slowly</span></code>). Khi xây dựng xong cây quyết định đầu tiên, chúng ta
sẽ xây dựng cây quyết định tiếp theo sử dụng biến đầu ra là phần dư
(residuals) của cây trước đó. Sau đó, sẽ xây dựng các cây quyết định
tiếp theo để update residuals. Mỗi cây có thể có kích thước nhỏ, với chỉ
một vài terminal nodes được quyết định bởi tham số d trong thuật toán.
Bằng việc xây dựng những cây nhỏ với residuals, chúng ta có thể dần dần
cải thiện fˆ. Tham số <code class="docutils literal notranslate"><span class="pre">shrinkage</span></code> hay <code class="docutils literal notranslate"><span class="pre">learning</span> <span class="pre">rate</span></code>(tốc độ học
của mô hình) λ sẽ làm mô hình “học” chậm và kỹ hơn nữa giúp cải thiện
chất lượng mô hình. Lưu ý rằng khác với bagging, đối với boosting thì
việc xây dựng các cây quyết định tiếp theo sẽ phụ thuộc vào kết quả của
các cây trước đó.</p>
<p>Như vậy, chúng ta đã vừa cùng tìm hiểu về boosting regression trees. Bây
giờ chúng sẽ cùng tìm hiểu về 2 thuật toán trong boosting là
<code class="docutils literal notranslate"><span class="pre">Adaboost</span></code> và <code class="docutils literal notranslate"><span class="pre">Gradient</span> <span class="pre">Boosting</span></code>.</p>
<p><strong>AdaBoost</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">AdaBoost</span></code> kết hợp các “weak learners” để tạo thành “strong learner”
(“weak learners” được hiểu là các cây phân loại chỉ tốt hơn một chút so
với việc đoán ngẫu nhiên). Sau mỗi bước lặp, những quan sát bị phân loại
sai sẽ được đánh trọng số cao hơn, những quan sát được phân loại đúng sẽ
đánh trọng số thấp hơn. Mỗi cây tiếp theo được xây dựng với mục tiêu
phân loại đúng những quan sát đã bị phân loại sai ở cây trước đó.</p>
<p>Chúng ta sẽ mô tả thuật toán <code class="docutils literal notranslate"><span class="pre">Adaboost</span></code> thông qua việc sử dụng ví dụ
sau đây: Phân loại các quan sát vào 2 nhóm <code class="docutils literal notranslate"><span class="pre">+</span></code> hoặc <code class="docutils literal notranslate"><span class="pre">-</span></code>. Chúng ta sẽ
thực hiện các bước sau:</p>
<hr class="docutils" />
<p><img alt="image1" src="./Images/tree-3.jpg" /></p>
<hr class="docutils" />
<p><em>Diễn giải</em>:</p>
<ul class="simple">
<li>Box 1: Đánh trọng số bằng nhau đối với tất cả quan sát và xây dựng
một decision stump - D1 (cây chỉ gồm 1 split hay 1 tầng) để phân loại
các quan sát thành 2 nhóm <code class="docutils literal notranslate"><span class="pre">+</span></code> và <code class="docutils literal notranslate"><span class="pre">-</span></code>. Kết quả cho thấy có 3 quan
sát bị phân loại sai (là <code class="docutils literal notranslate"><span class="pre">+</span></code> nhưng lại bị cho vào nhóm <code class="docutils literal notranslate"><span class="pre">-</span></code>), 3
quan sát này sẽ được đánh trọng số cao hơn và tiếp tục xây dựng
decision stump khác - D2.</li>
<li>Box 2: D2 được xây dựng với mục đích phân loại đúng 3 quan sát bị
phân loại sai ở D1. Kết quả cho thấy, lại có 3 quan sát bị phân loại
sai (là <code class="docutils literal notranslate"><span class="pre">-</span></code> nhưng bị cho vào nhóm <code class="docutils literal notranslate"><span class="pre">+</span></code>). Lại tiếp tục đánh trọng
số cao hơn đối với những quan sát này và tiếp tục xây dựng decision
stump - D3.</li>
<li>Box 3: D3 được xây dựng với mục đích phân loại đúng 3 quan sát bị
phân loại sai ở D2. Kết quả cho thấy vẫn có những quan sát bị phân
loại sai.</li>
<li>Box 4: Kết hợp D1, D2, D3 để tạo thành D4 - phân loại tốt hơn so với
D1, D2, D3 (nhóm <code class="docutils literal notranslate"><span class="pre">+</span></code> và <code class="docutils literal notranslate"><span class="pre">-</span></code> đã được phân loại hoàn toàn).</li>
</ul>
<p><strong>Gradient Boosting</strong></p>
<p>Gradient Boosting = Gradient Descent + Boosting</p>
<p>Cả <code class="docutils literal notranslate"><span class="pre">AdaBoost</span></code> và <code class="docutils literal notranslate"><span class="pre">Gradient</span> <span class="pre">Boosting</span></code> đều kết hợp các “weak learners”
để tạo thành một “strong learner” và đều tập trung vào những quan sát bị
dự báo sai. AdaBoost thì đánh trong số cao hơn vào những quan sát bị dự
báo sai tại mỗi cây trước, và cố gắng dự báo đúng những quan sát đó tại
cây tiếp theo. Trong khi đó, với Gradient Boosting, mỗi một cây mới sẽ
được xây dựng với mục tiêu tối thiểu hóa dần tổng loss của cây trước đó
bằng việc sử dụng phương pháp <code class="docutils literal notranslate"><span class="pre">gradient</span> <span class="pre">descent</span></code>.</p>
<p>Trong Gradient Boosting, việc tính tổng loss dựa vào việc lựa chọn loại
“loss function” nào, ví dụ như: square loss, absolute loss, huber loss.
Mỗi loại đều có những ưu/nhược điểm riêng.</p>
<ul class="simple">
<li>Square loss:</li>
</ul>
<div class="math notranslate">
\[L(y,F) = (y-F)^2/2\]</div>
<ul class="simple">
<li>Absolute loss:</li>
</ul>
<div class="math notranslate">
\[L(y,F) = |y-F|\]</div>
<ul class="simple">
<li>Huber loss:</li>
</ul>
<div class="math notranslate">
\[\begin{split}\begin{cases}(y-F)^2/2 &amp; |x-F| \leqslant \delta\\\delta(|y-F| - \delta/2) &amp; |x-F| &gt; \delta\end{cases}\end{split}\]</div>
<p><em>Ví dụ</em>:</p>
<p><img alt="image2" src="./Images/tree-5.jpg" /></p>
<hr class="docutils" />
<p>Boosting có 3 tham số cơ bản để tối ưu hóa mô hình
(<code class="docutils literal notranslate"><span class="pre">tuning</span> <span class="pre">parameters</span></code>):</p>
<ul class="simple">
<li>Số lượng cây quyết định (B): Với boosting khi số lượng cây quá nhiều
có thể dẫn đến overfitting, nên chúng ta sẽ sử dụng cross-validation
để lựa chọn số lượng cây</li>
<li>Tốc độ học λ (<code class="docutils literal notranslate"><span class="pre">learning</span> <span class="pre">rate</span></code> hoặc <code class="docutils literal notranslate"><span class="pre">shrinkage</span></code>): Giá trị nhỏ,
dương. λ có thể nhận các giá trị như: 0.1, 0.01, hay 0.001 tùy từng
trường hợp. λ càng nhỏ thì mô hình sẽ “học” càng chậm, càng lâu.</li>
<li>Số lần splits, hay phân nhánh (d) của mỗi cây: Tham số này dùng để
kiểm soát độ phức tạp của mô hình. Tham số này còn có thể gọi là số
tầng cây (<code class="docutils literal notranslate"><span class="pre">interactive</span> <span class="pre">depth</span></code>). Nếu d = 1 (tức cây chỉ có 1 tầng
hay 1 split) thì cây quyết định đó được gọi là <code class="docutils literal notranslate"><span class="pre">stump</span></code>.</li>
</ul>
<p>Để thực hành xây dựng mô hình boosting trên <code class="docutils literal notranslate"><span class="pre">R</span></code>, chúng ta sẽ sử dụng
dữ liệu có sẵn trong <code class="docutils literal notranslate"><span class="pre">R</span></code> - <code class="docutils literal notranslate"><span class="pre">GermanCredit</span></code>.</p>
<p>Đây là dữ liệu ghi nhận về lịch sử vay của khách hàng, với các 61 biến
đầu vào cùng với biến đầu ra <code class="docutils literal notranslate"><span class="pre">Class</span></code> ghi nhận thực tế là các khoản vay
đó có phải là khoản nợ xấu hay không.</p>
<p>Để xây dựng mô hình boosting trên <code class="docutils literal notranslate"><span class="pre">R</span></code>, chúng ta sẽ sử dụng hàm
<code class="docutils literal notranslate"><span class="pre">gbm()</span></code> trong package <strong>gbm</strong>.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kn">library</span><span class="p">(</span>caret<span class="p">)</span>
data<span class="p">(</span><span class="s">&quot;GermanCredit&quot;</span><span class="p">)</span>
data <span class="o">&lt;-</span> GermanCredit
<span class="kp">rm</span><span class="p">(</span>GermanCredit<span class="p">)</span>

<span class="c1"># Hàm tính toán các chỉ số đo lường chất lượng dự báo của mô hình</span>
model.performance <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>confusion_matrix<span class="p">)</span> <span class="p">{</span>
  a <span class="o">&lt;-</span> confusion_matrix<span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">]</span>
  b <span class="o">&lt;-</span> confusion_matrix<span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">]</span>
  <span class="kt">c</span> <span class="o">&lt;-</span> confusion_matrix<span class="p">[</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">]</span>
  d <span class="o">&lt;-</span> confusion_matrix<span class="p">[</span><span class="m">2</span><span class="p">,</span><span class="m">1</span><span class="p">]</span>

  tpr <span class="o">&lt;-</span> <span class="kt">c</span><span class="o">/</span><span class="p">(</span>b<span class="o">+</span><span class="kt">c</span><span class="p">)</span>
  precision <span class="o">&lt;-</span> <span class="kt">c</span><span class="o">/</span><span class="p">(</span><span class="kt">c</span><span class="o">+</span>d<span class="p">)</span>
  accuracy <span class="o">&lt;-</span> <span class="p">(</span>a<span class="o">+</span><span class="kt">c</span><span class="p">)</span><span class="o">/</span><span class="p">(</span>a<span class="o">+</span>b<span class="o">+</span><span class="kt">c</span><span class="o">+</span>d<span class="p">)</span>

  <span class="kp">print</span><span class="p">(</span><span class="kp">paste</span><span class="p">(</span><span class="s">&#39;recall :&#39;</span><span class="p">,</span><span class="kp">round</span><span class="p">(</span>tpr<span class="p">,</span><span class="m">2</span><span class="p">)))</span>
  <span class="kp">print</span><span class="p">(</span><span class="kp">paste</span><span class="p">(</span><span class="s">&#39;precision :&#39;</span><span class="p">,</span> <span class="kp">round</span><span class="p">(</span>precision<span class="p">,</span><span class="m">2</span><span class="p">)))</span>
  <span class="kp">print</span><span class="p">(</span><span class="kp">paste</span><span class="p">(</span><span class="s">&#39;accuracy :&#39;</span><span class="p">,</span><span class="kp">round</span><span class="p">(</span>accuracy<span class="p">,</span><span class="m">2</span><span class="p">)))</span>
<span class="p">}</span>

<span class="c1"># Chia data: training/testing tỷ lệ 8/2</span>
<span class="kp">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span>
indxTrain <span class="o">&lt;-</span> createDataPartition<span class="p">(</span>y <span class="o">=</span> data<span class="o">$</span>Class<span class="p">,</span>p <span class="o">=</span> <span class="m">8</span><span class="o">/</span><span class="m">10</span><span class="p">,</span><span class="kt">list</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span>
training <span class="o">&lt;-</span> data<span class="p">[</span>indxTrain<span class="p">,]</span>
testing <span class="o">&lt;-</span> data<span class="p">[</span><span class="o">-</span>indxTrain<span class="p">,]</span>

df.train <span class="o">&lt;-</span> training
df.train<span class="o">$</span>Status<span class="p">[</span>df.train<span class="o">$</span>Class <span class="o">==</span> <span class="s">&quot;Good&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="m">1</span>
df.train<span class="o">$</span>Status<span class="p">[</span>df.train<span class="o">$</span>Class <span class="o">==</span> <span class="s">&quot;Bad&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="m">0</span>

df.test <span class="o">&lt;-</span> testing
df.test<span class="o">$</span>Status<span class="p">[</span>df.test<span class="o">$</span>Class <span class="o">==</span> <span class="s">&quot;Good&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="m">1</span>
df.test<span class="o">$</span>Status<span class="p">[</span>df.test<span class="o">$</span>Class <span class="o">==</span> <span class="s">&quot;Bad&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="m">0</span>

<span class="kp">rm</span><span class="p">(</span>training<span class="p">,</span> testing<span class="p">)</span>

<span class="c1"># Gradient Boosting</span>
<span class="kp">set.seed</span><span class="p">(</span><span class="m">9999</span><span class="p">)</span>

<span class="c1"># Xây dựng mô hình trên tập train</span>
<span class="kn">library</span><span class="p">(</span>gbm<span class="p">)</span>
gbm.train <span class="o">&lt;-</span> gbm<span class="p">(</span>Status <span class="o">~</span> <span class="m">.</span> <span class="o">-</span> Class<span class="p">,</span>
                 data <span class="o">=</span> df.train<span class="p">,</span>
                 distribution <span class="o">=</span> <span class="s">&quot;bernoulli&quot;</span><span class="p">,</span>
                 n.trees <span class="o">=</span> <span class="m">1000</span><span class="p">,</span>
                 shrinkage <span class="o">=</span> <span class="m">0.01</span><span class="p">,</span>
                 interaction.depth <span class="o">=</span> <span class="m">4</span><span class="p">)</span>

<span class="c1"># Dự báo quan sát trên tập test</span>
gbm.result <span class="o">&lt;-</span> predict<span class="p">(</span>gbm.train<span class="p">,</span>
                      newdata <span class="o">=</span> df.test<span class="p">,</span>
                      n.trees <span class="o">=</span> <span class="m">1000</span><span class="p">,</span>
                      type <span class="o">=</span> <span class="s">&quot;response&quot;</span><span class="p">)</span>


<span class="c1"># Confusion matrix</span>
gbm.conf  <span class="o">&lt;-</span>  rep <span class="p">(</span><span class="s">&quot;Bad&quot;</span><span class="p">,</span> <span class="m">200</span><span class="p">)</span>
gbm.conf<span class="p">[</span>gbm.result <span class="o">&gt;</span> <span class="m">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;Good&quot;</span>
gbm.confusion <span class="o">&lt;-</span> <span class="kp">table</span><span class="p">(</span>gbm.conf<span class="p">,</span> df.test<span class="o">$</span>Class<span class="p">)</span>
gbm.confusion
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##</span>
<span class="c1">## gbm.conf Bad Good</span>
<span class="c1">##     Bad   35   16</span>
<span class="c1">##     Good  25  124</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>model.performance<span class="p">(</span>gbm.confusion<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## [1] &quot;recall : 0.89&quot;</span>
<span class="c1">## [1] &quot;precision : 0.83&quot;</span>
<span class="c1">## [1] &quot;accuracy : 0.8&quot;</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="m">35+124+25+16</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## [1] 200</span>
</pre></div>
</div>
<ul class="simple">
<li>Kết quả <code class="docutils literal notranslate"><span class="pre">confusion</span> <span class="pre">matrix</span></code> trên tập dữ liệu testing cho chúng ta
thấy:<ul>
<li>Tỷ lệ dự báo đúng trên tổng quan sát là 80% (tức 35 khách hàng có
nợ xấu và 124 khách hàng không có nợ xấu được dự báo đúng trên
tổng số 200 khách hàng trên tập dữ liệu testing)</li>
<li>Trong số 140 khách hàng thực tế không có nợ xấu thì chúng ta dự
báo chính xác 124 khách hàng (tỷ lệ 124/140 = 89%)</li>
<li>Trong số 149 khách hàng mà chúng ta dự báo là không có nợ xấu, có
124 khách hàng được dự báo chính xác (tỷ lệ 124/149 = 83%)</li>
</ul>
</li>
</ul>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># ROC</span>
<span class="kn">library</span><span class="p">(</span>ROCR<span class="p">)</span> <span class="c1"># Dùng để vẽ đường ROC và tính toán AUC</span>
gbm.ROC <span class="o">&lt;-</span> prediction<span class="p">(</span>gbm.result<span class="p">,</span> df.test<span class="o">$</span>Class<span class="p">)</span>
gbm.ROCperf_test <span class="o">&lt;-</span> performance<span class="p">(</span>gbm.ROC<span class="p">,</span> <span class="s">&quot;tpr&quot;</span><span class="p">,</span> <span class="s">&quot;fpr&quot;</span><span class="p">)</span>

<span class="c1"># Vẽ ROC</span>
plot<span class="p">(</span>gbm.ROCperf_test<span class="p">)</span>
</pre></div>
</div>
<p><img alt="image3" src="p03-05-bagging-boosting_files/figure-html/unnamed-chunk-4-1.png" /></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tính toán AUC</span>
gbm.auc_test <span class="o">&lt;-</span> performance<span class="p">(</span>gbm.ROC<span class="p">,</span> <span class="s">&quot;auc&quot;</span><span class="p">,</span> <span class="s">&quot;cutoff&quot;</span><span class="p">)</span>
gbm.auc_test<span class="o">@</span>y.values
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## [[1]]</span>
<span class="c1">## [1] 0.8171429</span>
</pre></div>
</div>
<ul class="simple">
<li>Kết quả <code class="docutils literal notranslate"><span class="pre">AUC</span> <span class="pre">~</span> <span class="pre">82%</span></code> trên tập testing cho thấy chất lượng dự báo của
mô hình là tương đối tốt.</li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="p03-07-xay-dung-mo-hinh-voi-h2o.html" class="btn btn-neutral float-right" title="6. Xây dựng mô hình với H2O" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="p03-04-decision-tree.html" class="btn btn-neutral float-left" title="4. Cây quyết định" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Anh Hoang Duc

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>