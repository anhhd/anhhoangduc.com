

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="vi" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="vi" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>4. Cây quyết định &mdash; Tài liệu Phân tích dữ liệu với R 2019</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'./',
              VERSION:'2019',
              LANGUAGE:'vi',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="_static/copybutton.js"></script>
        <script type="text/javascript" src="_static/translations.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Tìm Kiếm" href="search.html" />
    <link rel="next" title="5. Bagging, RandomForest và Boosting" href="p03-05-bagging-boosting.html" />
    <link rel="prev" title="3. Mô hình hồi quy logistic" href="p03-03-logistic-regression.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Phân tích dữ liệu với R
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Giới thiệu</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p01-01-gioi-thieu.html">Khoa học dữ liệu và nghề phân tích dữ liệu</a></li>
</ul>
<p class="caption"><span class="caption-text">Phân tích khám phá dữ liệu</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p02-03-bien-doi-du-lieu-dplyr.html">1. Ngữ pháp của biến đổi dữ liệu với DPLYR</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-04-phan-ra-va-xoay-chieu-du-lieu.html">2. Phân rã và xoay chiều dữ liệu</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-05-cac-chi-so-thong-ke.html">3. Các chỉ số thống kê mô tả cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-06-lap-trinh-ham.html">4. Lập trình hàm</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-07-lap-trinh-ham-voi-purrr.html">5. Lập trình chức năng hàm với purrr</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-08-bien-doi-du-lieu-text.html">6. Biến đổi dữ liệu text</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-11-quan-ly-nhieu-mo-hinh.html">7. Quản lý kết quả phân tích từ nhiều mô hình</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-15-thong-ke-co-ban.html">8. Xác suất và phân phối thống kê cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-16-power-analysis.html">9. Power analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-20-sampling-methods.html">10. Phương pháp ước lượng lấy mẫu</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-50-datatable.html">11. Biến đổi dữ liệu với <code class="docutils literal notranslate"><span class="pre">data.table</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-60-thu-thap-du-lieu-tu-website.html">12. Thu thập dữ liệu từ website</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-99-meo-trong-r.html">13. Các mẹo trong R</a></li>
</ul>
<p class="caption"><span class="caption-text">Supervised learning</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="p03-01-nguyen-ly-du-bao.html">1. Các nguyên lý dự báo</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-02-mo-hinh-ols.html">2. Mô hình OLS</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-03-logistic-regression.html">3. Mô hình hồi quy logistic</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">4. Cây quyết định</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#gioi-thieu">4.1. Giới thiệu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#regression-trees">4.2. Regression Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="#classification-trees">4.3. Classification Trees</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="p03-05-bagging-boosting.html">5. Bagging, RandomForest và Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-07-xay-dung-mo-hinh-voi-h2o.html">6. Xây dựng mô hình với H2O</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-08-svm.html">7. Support Vector Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-09-feature-engineering.html">8. Feature Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-15-regularization.html">9. Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-17-nonlinear.html">10. Mô hình phi tuyến tính</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-30-credit-scoring.html">11. Credit Scoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-35-caret.html">12. Xây dựng mô hình dự báo với caret</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-65-chat-luong-mo-hinh.html">13. Chất lượng mô hình</a></li>
<li class="toctree-l1"><a class="reference internal" href="p03-70-tidymodels.html">14. Tidymodels</a></li>
</ul>
<p class="caption"><span class="caption-text">Unsupervised learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p04-01-unsupervised-learning.html">1. Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-02-kmeans.html">2. k-means</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-03-hierarchical-clustering.html">3. Hierachical clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-04-basket-analysis.html">4. Phân tích giỏ hàng</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-05-pca.html">5. Principal component analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="p04-06-factor-analysis.html">6. Phân tích nhân tố ẩn (factor analysis)</a></li>
</ul>
<p class="caption"><span class="caption-text">Chuỗi thời gian</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p05-01-chuoi-thoi-gian.html">1. Giới thiệu về chuỗi thời gian</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-02-arima.html">2. Mô hình ARIMA</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-03-phan-tich-chuoi-thoi-gian-voi-tidyquant.html">3. Phân tích chuỗi thời gian với tidyquant và timetk</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-06-du-bao-ts-voi-prophet.html">4. Dự báo chuỗi thời gian với prophet</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-07-du-bao-ts-voi-timetk.html">5. Dự báo chuỗi thời gian với timetk</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-08-abnomaly-detection.html">6. Abnomaly detection trong times series</a></li>
</ul>
<p class="caption"><span class="caption-text">Ngôn ngữ tự nghiên</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p06-01-nlp-co-ban.html">1. Xử lý ngôn ngữ tự nhiên cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p06-04-text-classification.html">2. Phân loại text</a></li>
<li class="toctree-l1"><a class="reference internal" href="p06-07-nlp-api.html">3. Sử dụng API từ các dịch vụ đám mây</a></li>
<li class="toctree-l1"><a class="reference internal" href="p06-10-ocr-tesseract.html">4. OCR với <code class="docutils literal notranslate"><span class="pre">tesseract</span></code></a></li>
</ul>
<p class="caption"><span class="caption-text">Các phương pháp khác</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p07-01-survival-analysis.html">1. Survival analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-02-causal-impact.html">2. Causal Impact</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-03-collaborative-filtering.html">3. Collaborative Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-07-spatial-data.html">4. Spatial data</a></li>
<li class="toctree-l1"><a class="reference internal" href="p07-10-shiny.html">5. Shiny apps</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p09-01-gioi-thieu-deep-learning.html">1. Giới thiệu cơ bản về Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="p09-02-co-ban-kien-thuc-toan.html">2. Kiến thức cơ bản toán học cho deep learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="p09-03-mo-hinh-deep-learning-co-ban.html">3. Mô hình deep learning cơ bản</a></li>
<li class="toctree-l1"><a class="reference internal" href="p09-04-convolution-neural-network.html">4. Convolution neural networks</a></li>
</ul>
<p class="caption"><span class="caption-text">Cloud Computing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p10-01-cai-dat-rstudio-server-tren-amazon.html">1. Cài đặt server RStudio trên Amazon</a></li>
<li class="toctree-l1"><a class="reference internal" href="p10-03-web-service-azure.html">2. Xây dựng web service với Azure</a></li>
<li class="toctree-l1"><a class="reference internal" href="p10-09-apis-voi-plumber.html">3. API với Plumber</a></li>
</ul>
<p class="caption"><span class="caption-text">Kiến thức bổ trợ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p11-01-git.html">1. Sử dụng GIT</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-02-cmd.html">2. CMD và Bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-03-docker.html">3. Sử dụng docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-04-apis.html">4. API</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-05-html-css.html">5. Cơ bản về HTML và CSS</a></li>
<li class="toctree-l1"><a class="reference internal" href="p11-09-other.html">6. Các tricks khác</a></li>
</ul>
<p class="caption"><span class="caption-text">Case studies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="p13-01-casestudy-truc-quan-hoa.html">1. Trực quan hóa dữ liệu</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Phân tích dữ liệu với R</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>4. Cây quyết định</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/p03-04-decision-tree.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="cay-quyet-dinh">
<h1>4. Cây quyết định<a class="headerlink" href="#cay-quyet-dinh" title="Permalink to this headline">¶</a></h1>
<p>Trong chương này, chúng ta sẽ sẽ tìm hiểu về những phương pháp dựa vào
cây quyết định (<code class="docutils literal notranslate"><span class="pre">tree-based</span></code> methods) để giải quyết những bài toán hồi
quy (<code class="docutils literal notranslate"><span class="pre">regression</span></code>) cũng như những bài toán phân loại
(<code class="docutils literal notranslate"><span class="pre">classification</span></code>). Các phương pháp này sẽ nhóm các quan sát vào một
số vùng (<code class="docutils literal notranslate"><span class="pre">regions</span></code>) nhất định, và để dự báo một quan sát mới, chúng ta
thường sử dụng giá trị trung bình (đối với bài toán hồi quy) hoặc giá
trị mode, hay majority vote (đối với bài toán phân loại) của những quan
sát tập dữ liệu training trong vùng mà quan sát đó thuộc về.</p>
<p>Trong chương này, chúng ta sẽ được giới thiệu lần lượt các phương pháp
<code class="docutils literal notranslate"><span class="pre">tree-based</span></code> điển hình như: <code class="docutils literal notranslate"><span class="pre">decision</span> <span class="pre">trees</span></code>, <code class="docutils literal notranslate"><span class="pre">bagging</span></code>,
<code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code> và <code class="docutils literal notranslate"><span class="pre">boosting</span></code>.</p>
<div class="section" id="gioi-thieu">
<h2>4.1. Giới thiệu<a class="headerlink" href="#gioi-thieu" title="Permalink to this headline">¶</a></h2>
<p>Phương pháp <code class="docutils literal notranslate"><span class="pre">decision</span> <span class="pre">trees</span></code> (cây quyết định) gồm tập hợp các nguyên
tắc phân nhóm (<code class="docutils literal notranslate"><span class="pre">spliting</span> <span class="pre">rules</span></code>) được sử dụng để nhóm các quan sát vào
một số vùng (<code class="docutils literal notranslate"><span class="pre">regions</span></code>) nhất định mà được thống kê trong một cây.</p>
<p>Phương pháp <code class="docutils literal notranslate"><span class="pre">decision</span> <span class="pre">trees</span></code> có thể áp dụng đối với cả hai bài toán
hồi quy (regression) và phân loại (classification).</p>
<center><p><img alt="image0" src="./Images/tree-0.jpg" /></p>
</center></div>
<hr class="docutils" />
<div class="section" id="regression-trees">
<h2>4.2. Regression Trees<a class="headerlink" href="#regression-trees" title="Permalink to this headline">¶</a></h2>
<p>Phương pháp cây quyết định hồi quy (regression trees) dùng cho trường
hợp khi biến đầu ra chúng ta muốn dự báo là biến liên tục hay biến định
lượng</p>
<p>Chúng ta sẽ sử dụng dữ liệu có sẵn trong <code class="docutils literal notranslate"><span class="pre">R</span></code> - <code class="docutils literal notranslate"><span class="pre">Hitters</span></code> trong
packge <strong>ISLR</strong> để dự báo thu nhập của cầu thủ bóng chày (<code class="docutils literal notranslate"><span class="pre">salary</span></code>)
dựa vào số năm chơi bóng tại các giải đấu lớn (<code class="docutils literal notranslate"><span class="pre">years</span></code>) và số điểm ghi
được trong mùa giải trước (<code class="docutils literal notranslate"><span class="pre">hits</span></code>).</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kn">library</span><span class="p">(</span>ISLR<span class="p">)</span>
<span class="kn">library</span><span class="p">(</span>tidyverse<span class="p">)</span>

data<span class="p">(</span><span class="s">&quot;Hitters&quot;</span><span class="p">)</span>
<span class="kp">names</span><span class="p">(</span>Hitters<span class="p">)</span> <span class="o">&lt;-</span> <span class="kp">names</span><span class="p">(</span>Hitters<span class="p">)</span> <span class="o">%&gt;%</span> <span class="kp">tolower</span>

<span class="c1"># Lấy 3 biến: `years`, `hits`, `salary`</span>
data <span class="o">&lt;-</span> Hitters <span class="o">%&gt;%</span>
  select<span class="p">(</span>years<span class="p">,</span>hits<span class="p">,</span>salary<span class="p">)</span>
</pre></div>
</div>
<p>Đầu tiên chúng ta sẽ loại bỏ những quan sát bị missing ở biến
<code class="docutils literal notranslate"><span class="pre">salary</span></code>, và lấy log của biến <code class="docutils literal notranslate"><span class="pre">salary</span></code> để biến này tiệm cận với phân
phối chuẩn hơn (phân phối hình chuông). Biến <code class="docutils literal notranslate"><span class="pre">salary</span></code> đơn vị là nghìn
USD.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>data_new <span class="o">&lt;-</span> data <span class="o">%&gt;%</span>
  <span class="c1"># Loại bỏ giá trị missing ở biến `salary`</span>
  filter<span class="p">(</span><span class="o">!</span><span class="kp">is.na</span><span class="p">(</span>salary<span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="c1"># log-transform</span>
  mutate<span class="p">(</span>salary <span class="o">=</span> <span class="kp">log</span><span class="p">(</span>salary<span class="p">))</span>

<span class="c1"># Biểu đồ phân phối biến `salary` của `data`</span>
data <span class="o">%&gt;%</span>
  ggplot<span class="p">(</span>aes<span class="p">(</span>salary<span class="p">))</span><span class="o">+</span>
  geom_density<span class="p">()</span><span class="o">+</span>
  theme_minimal<span class="p">()</span>
</pre></div>
</div>
<p><img alt="image1" src="p03-04-decision-tree_files/figure-html/unnamed-chunk-3-1.png" /></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Biểu đồ phân phối biến `salary` của `data_new`</span>
data_new <span class="o">%&gt;%</span>
  ggplot<span class="p">(</span>aes<span class="p">(</span>salary<span class="p">))</span><span class="o">+</span>
  geom_density<span class="p">()</span><span class="o">+</span>
  theme_minimal<span class="p">()</span>
</pre></div>
</div>
<p><img alt="image2" src="p03-04-decision-tree_files/figure-html/unnamed-chunk-3-2.png" /></p>
<p>Giả sử chúng ta xây dựng một cây hồi quy (regression tree) với dữ liệu
nói trên và thu được kết quả như sau:</p>
<hr class="docutils" />
<center><p><img alt="image3" src="./Images/tree-1.jpg" /></p>
</center><hr class="docutils" />
<p>Với tập dữ liệu này, trung bình log-transform salary là 5.9, tức thu
nhâp trung bình của các cầu thủ bóng chày là exp(5.9) = 375 (nghìn USD).</p>
<p>Cây quyết định trên bao gồm tập hợp các nguyên tắc phân nhóm
(<code class="docutils literal notranslate"><span class="pre">spliting</span> <span class="pre">rules</span></code>), bắt đầu từ trên xuống dưới.</p>
<p>Với nguyên tắc phân nhóm đầu tiên <code class="docutils literal notranslate"><span class="pre">Years</span> <span class="pre">&lt;</span> <span class="pre">4.5</span></code> thì ở nhánh bên trái
là những quan sát thỏa mãn điều kiện trên, và trung bình log-transform
salary của nhóm này là 5.1. Nghĩa là, nhóm cầu thủ có số năm chơi bóng
tại các giải đấu lớn ít hơn 4.5 năm có mức thu nhập trung bình là
exp(5.1) = 164 (nghìn USD).</p>
<p>Còn đối với những cầu thủ mà chơi bóng từ 4.5 năm trở lên tại các giải
đấu lớn thì có thu nhập trung bình là exp(6.4) = 601 (nghìn USD). Tuy
nhiên nhóm này còn chia thành 2 nhóm nhỏ hơn với nguyên tắc phân nhóm
<code class="docutils literal notranslate"><span class="pre">Hits</span> <span class="pre">&lt;</span> <span class="pre">118</span></code>.</p>
<ul class="simple">
<li>Nhóm thỏa mãn điều kiện <code class="docutils literal notranslate"><span class="pre">Hits</span> <span class="pre">&lt;</span> <span class="pre">118</span></code> (số điểm ghi được trong mùa
giải trước ít hơn 118) có mức thu nhập trung bình là exp(6) = 403
(nghìn USD)</li>
<li>Nhóm ghi được từ 118 điểm trở lên tại mùa giải trước có mức thu nhập
trung bình là exp(6.7) = 812 (nghìn USD).</li>
</ul>
<p>Như vậy, cây quyết định nói trên đã phân loại các cầu thủ và 3 vùng/nhóm
(<code class="docutils literal notranslate"><span class="pre">regions</span> <span class="pre">of</span> <span class="pre">predictor</span> <span class="pre">space</span></code>):</p>
<ul class="simple">
<li>R1: years &lt; 4.5</li>
<li>R2: years &gt;= 4.5, hits &lt; 118</li>
<li>R3: years &gt;= 4.5, hits &gt;= 118</li>
</ul>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>data_new <span class="o">%&gt;%</span>
  ggplot<span class="p">(</span>aes<span class="p">(</span>years<span class="p">,</span>hits<span class="p">))</span> <span class="o">+</span>
  geom_point<span class="p">(</span>col <span class="o">=</span> <span class="s">&quot;gold&quot;</span><span class="p">)</span><span class="o">+</span>
  theme_bw<span class="p">()</span><span class="o">+</span>
  geom_vline<span class="p">(</span>aes<span class="p">(</span>xintercept <span class="o">=</span> <span class="m">4.5</span><span class="p">),</span> col <span class="o">=</span> <span class="s">&quot;blue&quot;</span><span class="p">,</span> size <span class="o">=</span> <span class="m">1</span><span class="p">)</span><span class="o">+</span>
  geom_segment<span class="p">(</span>aes<span class="p">(</span>x <span class="o">=</span> <span class="m">4.5</span><span class="p">,</span>
                   y <span class="o">=</span> <span class="m">118</span><span class="p">,</span>
                   xend <span class="o">=</span> <span class="kc">Inf</span><span class="p">,</span>
                   yend <span class="o">=</span> <span class="m">118</span>
                   <span class="p">),</span>
               col <span class="o">=</span> <span class="s">&quot;blue&quot;</span><span class="p">,</span>
               size <span class="o">=</span> <span class="m">1</span><span class="p">)</span><span class="o">+</span>
  theme<span class="p">(</span>panel.grid <span class="o">=</span> element_blank<span class="p">())</span><span class="o">+</span>
  scale_x_continuous<span class="p">(</span>breaks <span class="o">=</span> <span class="m">4.5</span><span class="p">)</span><span class="o">+</span>
  scale_y_continuous<span class="p">(</span>breaks <span class="o">=</span> <span class="m">118</span><span class="p">)</span><span class="o">+</span>
  theme<span class="p">(</span>axis.text <span class="o">=</span> element_text<span class="p">(</span>face <span class="o">=</span> <span class="s">&quot;bold&quot;</span><span class="p">,</span> size <span class="o">=</span> <span class="m">10</span><span class="p">))</span><span class="o">+</span>
  annotate<span class="p">(</span><span class="s">&quot;text&quot;</span><span class="p">,</span> x <span class="o">=</span> <span class="m">4.5</span><span class="o">/</span><span class="m">2</span><span class="p">,</span> y <span class="o">=</span> <span class="m">118</span><span class="p">,</span> label <span class="o">=</span> <span class="s">&quot;R1&quot;</span><span class="p">,</span> col <span class="o">=</span> <span class="s">&quot;red&quot;</span><span class="p">,</span> size <span class="o">=</span> <span class="m">6</span><span class="p">)</span><span class="o">+</span>
  annotate<span class="p">(</span><span class="s">&quot;text&quot;</span><span class="p">,</span> x <span class="o">=</span> <span class="p">(</span><span class="m">32-4.5</span><span class="p">)</span><span class="o">/</span><span class="m">2</span><span class="p">,</span> y <span class="o">=</span> <span class="m">118</span><span class="o">/</span><span class="m">2</span><span class="p">,</span> label <span class="o">=</span> <span class="s">&quot;R2&quot;</span><span class="p">,</span> col <span class="o">=</span> <span class="s">&quot;red&quot;</span><span class="p">,</span> size <span class="o">=</span> <span class="m">6</span><span class="p">)</span><span class="o">+</span>
  annotate<span class="p">(</span><span class="s">&quot;text&quot;</span><span class="p">,</span> x <span class="o">=</span> <span class="p">(</span><span class="m">32-4.5</span><span class="p">)</span><span class="o">/</span><span class="m">2</span><span class="p">,</span> y <span class="o">=</span> <span class="m">118</span><span class="o">*</span><span class="m">1.5</span><span class="p">,</span> label <span class="o">=</span> <span class="s">&quot;R3&quot;</span><span class="p">,</span> col <span class="o">=</span> <span class="s">&quot;red&quot;</span><span class="p">,</span> size <span class="o">=</span> <span class="m">6</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="image4" src="p03-04-decision-tree_files/figure-html/unnamed-chunk-4-1.png" /></p>
<p>Mức thu nhập dự báo của 3 nhóm này lần lượt là 164,000 USD, 403,000 USD,
812,000 USD.</p>
<p>Trong ví dụ này R1, R2, R3 ở đây được gọi là <code class="docutils literal notranslate"><span class="pre">terminal</span> <span class="pre">nodes</span></code> hoặc
<code class="docutils literal notranslate"><span class="pre">leaves</span></code> (lá cây). <code class="docutils literal notranslate"><span class="pre">years</span> <span class="pre">&lt;</span> <span class="pre">4.5</span></code> và <code class="docutils literal notranslate"><span class="pre">hits</span> <span class="pre">&lt;</span> <span class="pre">118</span></code> được gọi là
<code class="docutils literal notranslate"><span class="pre">internal</span> <span class="pre">nodes</span></code> hoặc <code class="docutils literal notranslate"><span class="pre">decision</span> <span class="pre">nodes</span></code>.</p>
<p>Chúng ta có thể diễn giải cây quyết định hồi quy nói trên như sau: Biến
<code class="docutils literal notranslate"><span class="pre">years</span></code> là quan trọng nhất ảnh hưởng tới việc dự báo <code class="docutils literal notranslate"><span class="pre">salary</span></code>. Nhóm
cầu thủ có số năm chơi bóng tại các giải đấu lớn nhiều hơn sẽ có mức thu
nhập cao hơn. Nhóm cầu thủ có số năm chơi bóng dưới 4.5 năm thì số điểm
họ ghi được trong mùa giải trước đấy không ảnh hưởng đến thu nhập của
họ, trong khi đó nhóm cầu thủ có số năm chơi bóng từ 4.5 năm trở lên tại
các giải đấu lớn thì ngược lại. Số điểm ghi được trong mùa giải trước đó
của nhóm cầu thủ này có ảnh hưởng đến thu nhập của họ, nhóm cầu thủ ghi
được từ 118 điểm trở lên có mức thu nhập cao hơn nhóm còn lại.</p>
<p>Bây giờ, chúng ta sẽ cùng tìm hiểu quá trình xây dựng cây quyết định hồi
quy (regression tree). Bao gồm 2 bước sau:</p>
<ul class="simple">
<li><strong>Bước 1</strong>: Chia các quan sát (tức tìm tập hợp những giá trị phù hợp
cho các biến X1, X2,…, Xp) vào j vùng/nhóm khác nhau
(non-overlapping) R1, R2,…, Rj.</li>
<li><strong>Bước 2</strong>: Với mỗi quan sát mà thuộc về vùng/nhóm Rj, chúng ta sẽ dự
báo chúng cùng một giá trị, bằng với trung bình các giá trị quan sát
ở tập dữ liệu training trong vùng/nhóm Rj.</li>
</ul>
<p>Như ví dụ về dự báo thu nhập của cầu thủ bóng chày nói trên, ở bước 1
chúng ta chia các cầu thủ thành 3 nhóm: R1, R2, R3. Thu nhập trung bình
của 3 nhóm trên lần lượt là 164,000 USD, 403,000 USD, 812,000 USD. Vậy
nếu một cầu thủ bất kỳ mà thuộc về R1, thì chúng ta sẽ dự báo thu nhập
của cầu thủ này là 164,000 USD, nếu thuộc về R2, thì dự báo là 403,000
USD, và nếu thuộc R3 - 812,000 USD.</p>
<p>Chúc ta sẽ cùng tìm hiểu sâu hơn về bước 1 nói trên. Làm thế nào để xây
dựng được các vùng/nhóm R1,.., Rj? Về lý thuyết, các vùng này có thể có
hình dạng bất kỳ. Tuy nhiên, chúng ta sẽ chia các quan sát (predictor
space) thành boxes (các hộp) để cho đơn giản và dễ giải thích kết quả dự
báo của mô hình. Mục đích là đi tìm boxes R1,…, Rj sao cho tối thiểu hóa
RSS (<strong>R</strong>esidual <strong>S</strong>um of <strong>S</strong>quares):</p>
<div class="math notranslate">
\[\sum_{j=1}^{J}\sum_{i \epsilon R_j}^{J}(y_i - \widehat{y}_{R_j})^2\]</div>
<p>Trong đó yRj là trung bình kết quả của những quan sát trên tập dữ liệu
training trong box thứ j.</p>
<p>Tuy nhiên việc tính toán biểu thức trên sẽ rất phức tạp, do vậy chúng ta
sẽ dùng cách tiếp cận <code class="docutils literal notranslate"><span class="pre">top-down</span></code>, <code class="docutils literal notranslate"><span class="pre">greedy</span></code> hay còn được gọi là
<code class="docutils literal notranslate"><span class="pre">recursive</span> <span class="pre">binary</span> <span class="pre">splitting</span></code>. Sở dĩ cách tiếp cận trên là <code class="docutils literal notranslate"><span class="pre">top-down</span></code>
vì nó bắt đầu từ phần đỉnh của cây (nơi mà tất cả các quan sát thuộc một
nhóm ban đầu), sau đó sẽ phân nhóm các quan sát, mỗi sự phân nhóm sẽ
chia làm 2 nhánh (<code class="docutils literal notranslate"><span class="pre">branches</span></code>) mới xuống phía dưới. Còn việc nói cách
tiếp cận trên là <code class="docutils literal notranslate"><span class="pre">greedy</span></code> vì tại mỗi bước trong quá trình xây dựng
cây, sự phân nhóm tốt nhất (<code class="docutils literal notranslate"><span class="pre">best</span> <span class="pre">split</span></code>) sẽ được sử dụng.</p>
<p>Để có thể thực hiện cách tiếp cận <code class="docutils literal notranslate"><span class="pre">recursive</span> <span class="pre">binary</span> <span class="pre">splitting</span></code> nêu
trên, chúng ta đầu tiên sẽ lấy những biến Xj và cutpoint s để chia các
quan sát vào các vùng/nhóm {X|Xj &lt; s} và {X|Xj &gt;= s} sao cho tối thiểu
hóa RSS.</p>
<p>{X|Xj &lt; s} ở đây được hiểu là vùng bao gồm các quan sát mà thỏa mãn điều
kiện Xj &lt; s.</p>
<p>Nghĩa là, chúng ta sẽ xem xét tất cả các biến X1,…, Xp và tất cả các
cutpoint s cho mỗi biến, rồi sau đó sẽ lựa chọn những biến và cutpoint
để sao cho cây quyết định cuối cùng có RSS nhỏ nhất. Nói một cách tổng
quát hơn, với mọi giá trị j và s, chúng ta xác định cặp nửa mặt phẳng
sau:</p>
<div class="math notranslate">
\[R_1(j,s) = \lbrace X|X_j &lt; s \rbrace , R_2(j,s) = \lbrace X|X_j &gt;= s \rbrace\]</div>
<p>Và chúng ta sẽ đi tìm giá trị j và s để tối thiểu hóa biểu thức sau:</p>
<div class="math notranslate">
\[\sum_{i: x_i \epsilon R_1(j,s)}^{J}(y_i - \widehat{y}_{R_1})^2 + \sum_{i: x_i \epsilon R_2(j,s)}^{J}(y_i - \widehat{y}_{R_2})^2\]</div>
<p>Trong đó:</p>
<ul class="simple">
<li>yR1 - trung bình kết quả các quan sát trên tập dữ liệu training trong
R1(j,s)</li>
<li>yR2 - trung bình kết quả các quan sát trên tập dữ liệu training trong
R2(j,s)</li>
</ul>
<p>Việc tìm j và s sẽ khá nhanh, đặc biệt đối với trường hợp khi số lượng
biến p ít.</p>
<p>Tiếp theo đó, chúng ta sẽ lặp lại quá trình nói trên, lựa chọn biến tốt
nhất và cutpoint tốt nhất để tiếp tục split dữ liệu sao để tối thiểu hóa
RSS trong mỗi vùng/nhóm kết quả. Tuy nhiên, lần này thay vì việc chúng
ta split toàn bộ các quan sát, chúng ta chỉ split 1 trong 2 vùng/nhóm đã
được xác định trước đó. Như vậy, bây giờ chúng ta có 3 vùng/nhóm. Cứ
tiếp tục như vậy, chúng ta lại split 1 trong 3 vùng/nhóm này để tối
thiểu hóa RSS. Quá trình cứ tiếp tục diễn ra cho đến khi nó dừng lại
theo tiêu chí đặt ra của chúng ta, ví dụ chúng ta đặt điều kiện là sẽ
tiếp tục quá trình cho đến khi không có vùng/nhóm nào bao gồm nhiều hơn
10 quan sát.</p>
<p>Như vậy, các vùng R1, R2,…, Rj được tạo ra, chúng ta dự báo kết quả của
các quan sát mới bằng việc sử dụng giá trị trung bình kết quả các quan
sát trên tập dữ liệu training ở vùng/nhóm mà quan sát mới đó thuộc về.</p>
<p><strong>Tree Pruning</strong></p>
<p>Quá trình mô tả bên trên có thể dự báo tương đối chính xác trên tập dữ
liệu training, nhưng có thể thiếu chính xác trên tập dữ liệu testing,
vấn đề này được gọi là <strong>overfitting</strong>. Đó là bởi vì cây quyết định được
xây dựng quá phức tạp (nhiều splits). Cây quyết định nhỏ hơn với ít
splits hơn (ít vùng/nhóm hơn) có thể dẫn đến việc variance thấp hơn và
tính giải thích cao hơn. Để khắc phục vấn đề overfitting, chúng ta có
thể dùng kỹ thuật “tỉa” cây (<code class="docutils literal notranslate"><span class="pre">pruning</span></code>).</p>
<p>Cách tiếp cận tốt nhất là chúng ta sẽ xây dựng một cây lớn To, sau đó sẽ
“tỉa” (<code class="docutils literal notranslate"><span class="pre">prune</span></code>) cây để thành <code class="docutils literal notranslate"><span class="pre">subtree</span></code> (cây con). Nhưng làm thế nào
để xác định được cách “tỉa” cây tốt nhất? Theo trực giác, chúng ta sẽ
chọn subtree mà có tỷ lệ sai số thấp nhất trên tập dữ liệu mới (test
error rate). Khi subtree được xác định, chúng ta có thể ước lượng sai số
trên tập dữ liệu mới của subtree đó bằng việc sử dụng
<code class="docutils literal notranslate"><span class="pre">cross-validation</span></code> hoặc dữ liệu mới (<code class="docutils literal notranslate"><span class="pre">validation</span> <span class="pre">set</span></code>). Tuy nhiên
việc ước lượng cross-validation error cho từng subtree có thể có sẽ rất
phức tạp và tốn nhiều công sức, vì số lượng subtree có thể sẽ rất nhiều.
Thay vì việc đó, chúng ta cân nhắc việc lựa chọn một tập hợp nhỏ các
subtree để xem xét.</p>
<p><code class="docutils literal notranslate"><span class="pre">Cost</span> <span class="pre">complexity</span> <span class="pre">pruning</span></code>, còn gọi là <code class="docutils literal notranslate"><span class="pre">weakest</span> <span class="pre">link</span> <span class="pre">pruning</span></code> là một
cách để chúng ta thực hiện việc nói trên. Thay vì việc xem xét tất cả
các subtree có thể, chúng ta có thể xem xét một chuỗi các cây được
indexed bởi một tham số không âm α.</p>
<p>Thuật toán xây dựng cây quyết định hồi quy (regression tree):</p>
<ul class="simple">
<li><strong>Bước 1</strong>: Sử dụng <code class="docutils literal notranslate"><span class="pre">recursive</span> <span class="pre">binary</span> <span class="pre">splitting</span></code> để xây dựng một
cây lớn từ tập dữ liệu training, và chỉ dừng lại khi mỗi terminal
node có ít hơn một số lượng quan sát tối thiểu nhất định.</li>
<li><strong>Bước 2</strong>: Áp dụng <code class="docutils literal notranslate"><span class="pre">cost</span> <span class="pre">complexity</span> <span class="pre">pruning</span></code> để có được một chuỗi
các subtree tốt nhất, as a function of α.</li>
<li><strong>Bước 3</strong>: Sử dụng K-fold cross-validation để lựa chọn α. Tức là,
chia các quan sát của tập dữ liệu training vào K-fold. Với k = 1,…,
K:<ul>
<li>Lập lại bước 1 và 2 nhưng với k-th fold của tập dữ liệu training.</li>
<li>Tính toán mean squared prediction error on the data in the
left-out kth fold, as a function of α.</li>
</ul>
</li>
</ul>
<p>Tính trung bình các kết quả cho từng giá trị α, và chọn α để tối thiểu
hóa sai số trung bình (average error).</p>
<ul class="simple">
<li><strong>Bước 4</strong>: Lựa chọn subtree từ bước 2 mà tương ứng với việc lựa chọn
α.</li>
</ul>
<hr class="docutils" />
<p>Với mỗi giá trị α sẽ tương ứng với subtree T thuộc To mà:</p>
<div class="math notranslate">
\[\sum_{m=1}^{|T|}\sum_{i: x_i \epsilon R_m}^{J}(y_i - \widehat{y}_{R_m})^2 + α|T|\]</div>
<p>nhỏ nhất có thể. Ở đây, T - số lượng terminal nodes của cây, Rm -
rectangle (the subset of predictor space) tương ứng với terminal node
thứ m, yRm - giá trị dự báo (tức là trung bình các giá trị quan sát
trong Rm).</p>
<p>Tham số α sẽ kiểm soát sự đánh đổi giữa độ phức tạp của subtree và chất
lượng dự báo trên tập dữ liệu train. Nếu α = 0, thì subtree T = To, vì
biểu thức nói trên trở thành training error. Biểu thức trên làm chúng ta
liên tưởng đến <code class="docutils literal notranslate"><span class="pre">lasso</span></code> - một biểu thức tương tự dùng để kiểm soát độ
phức tạp của mô hình hồi quy tuyến tính.</p>
</div>
<div class="section" id="classification-trees">
<h2>4.3. Classification Trees<a class="headerlink" href="#classification-trees" title="Permalink to this headline">¶</a></h2>
<p>Cây quyết định phân loại (classification tree) tương tự như cây quyết
định hồi quy (regression tree), chỉ khác điểm đối với classification
tree thì biến đầu ra muốn dự báo là biến rời rạc hay biến định tính
(<code class="docutils literal notranslate"><span class="pre">categorical</span> <span class="pre">variable</span></code>) thay vì là biến liên tục như đối với
regression tree.</p>
<p>Đối với regression tree thì kết quả dự báo cho một quan sát mới chính là
trung bình kết quả của các giá trị quan sát trong tập dữ liệu training
tại vùng (region) mà quan sát đó thuộc về. Nhưng đối với classification
tree, kết quả dự báo cho một quan sát mới sẽ là giá trị mà có tần suất
xuất hiện nhiều nhất trong số các quan sát của tập dữ liệu training tại
vùng mà quan sát đó thuộc về.</p>
<p>Giả sử, chúng ta đã xây được một cây quyết định dự báo xem khách hàng có
trả được hết nợ hoặc không (tức biến đầu ra có 2 class là trả được nợ và
không trả được nợ). Và kết quả là cây quyết định đó chia thành khách
hàng vào 3 vùng (regions) khác nhau: A,B,C.</p>
<p>Bây giờ chúng ta đang muốn dự báo xem một khách hàng mới Nguyễn Văn T có
trả được nợ hay không dựa vào mô hình đã được xây dựng. Giả sử, với
những nguyên tắc phân nhóm (spliting rules) của cây quyết định, chúng ta
đã phân nhóm được khách hàng nói trên vào vùng A nhất định. Như vậy, nếu
trong các khách hàng thuộc vùng A trước đó, đa số là khách hàng trả được
nợ (tức số lượng khách hàng trả được nợ nhiều hơn số lượng khách hàng
không trả được nợ), thì chúng ta có thể dự báo rằng khách hàng mới nói
trên có trả được nợ.</p>
<p>Khi diễn giải kết quả của classification tree, chúng ta không chỉ quan
tâm đến class được dự báo tại mỗi vùng (region) nhất định mà còn quan
tâm đến <code class="docutils literal notranslate"><span class="pre">class</span> <span class="pre">propotions</span></code> giữa các quan sát trong tập dữ liệu
training mà thuộc về vùng đó. Như trong ví dụ trên, ngoài việc dự báo
được khách hàng thuộc vùng A sẽ có khả năng trả được nợ, chúng ta còn
muốn biết cụ thể tỷ lệ khách hàng trả được nợ và không trả được nợ tại
vùng A là bao nhiêu, và tỷ lệ khách hàng thuộc vùng A trên tổng số khách
hàng là bao nhiêu.</p>
<p>Cũng giống như regression tree, việc xây dựng classification tree cũng
sử dụng <code class="docutils literal notranslate"><span class="pre">recursive</span> <span class="pre">binary</span> <span class="pre">splitting</span></code>. Tuy nhiên đối với classification
tree, RSS không được sử dụng như một tiêu chí để làm phân nhóm nhị phân
(<code class="docutils literal notranslate"><span class="pre">binary</span> <span class="pre">splits</span></code>), thay vào đó là <code class="docutils literal notranslate"><span class="pre">classification</span> <span class="pre">error</span> <span class="pre">rate</span></code>. Khi
chúng ta đã xác định được quan sát mới vào class mà tần suất xuất hiện
nhiều nhất trong vùng mà quan sát đó thuộc về, classification error rate
sẽ chính là tỷ lệ số quan sát trên tập dữ liệu training trong vùng đó mà
không thuộc vào class đa số:</p>
<div class="math notranslate">
\[E = 1 - \max_k(\widehat{p}_{mk})\]</div>
<p>Ở đây pmk - tỷ trọng quan sát trên tập dữ liệu training trong vùng thứ m
từ class thứ k. Tuy nhiên, classification error đôi khi sẽ không hiệu
quả đối với một số trường hợp trong thực tế, vì vậy, có 2 thước đo khác
mà chúng ta nên sử dụng:</p>
<p>Chỉ số <code class="docutils literal notranslate"><span class="pre">Gini</span></code>:</p>
<div class="math notranslate">
\[G = \sum_{k=1}^{K}\widehat{p}_{mk}(1-\widehat{p}_{mk})\]</div>
<p>Đây là một chỉ số về tổng variance qua K classes. Dễ nhận thấy rằng chỉ
số Gini sẽ càng nhỏ nếu pmk tiếp cận 0 hoặc 1. Vì lý do đó chỉ số Gini
được coi là thước đo độ đồng nhất của node (node <code class="docutils literal notranslate"><span class="pre">purity</span></code>).</p>
<p>Một chỉ số khác thay thế cho chỉ số Gini là <code class="docutils literal notranslate"><span class="pre">cross-entropy</span></code>:</p>
<div class="math notranslate">
\[D = -\sum_{k=1}^{K}\widehat{p}_{mk}log(\widehat{p}_{mk})\]</div>
<p>pmk nhận giá trị từ 0 đến 1, nên -pmk*log(pmk) sẽ không âm.
Cross-entropy sẽ tiếp cận đến 0 nếu tất cả các giá trị pmk tiệm cận đến
0 hoặc 1. Vì vậy, cũng giống như chỉ số Gini, cross-entropy sẽ mang giá
trị nhỏ nếu như node thứ m đồng nhất.</p>
<p>Khi xây dựng classification tree, cả chỉ số Gini và cross-entropy đều
thường dùng để đánh giá chất lượng của split cụ thể nào đó. Hai chỉ số
trên more sensitive với node purity hơn là classification error rate. Cả
3 chỉ số trên đều có thể sử dụng để “tỉa” (prune) cây, nhưng
classification error rate sẽ được ưu tiên sử dụng khi chúng ta muốn tính
độ chính xác của dự báo (<code class="docutils literal notranslate"><span class="pre">prediction</span> <span class="pre">accuracy</span></code>) của cây quyết định
cuối cùng sau khi đã được “tỉa”.</p>
<hr class="docutils" />
<p>Như vậy, <code class="docutils literal notranslate"><span class="pre">classification</span> <span class="pre">tree</span></code> thiết lập một tập hợp các nguyên tắc
phân nhóm nhị phân (<code class="docutils literal notranslate"><span class="pre">binary</span> <span class="pre">splits</span></code>) với các biến đầu vào
(<code class="docutils literal notranslate"><span class="pre">predictor</span> <span class="pre">variables</span></code>) để xây dựng một cây quyết định sao cho có thể
phân loại (<code class="docutils literal notranslate"><span class="pre">classify</span></code>) những quan sát mới vào một trong hai nhóm xác
định.</p>
<p>Để thực hành xây dựng classification tree trên <code class="docutils literal notranslate"><span class="pre">R</span></code>, chúng ta sẽ sử
dụng dữ liệu <code class="docutils literal notranslate"><span class="pre">Default</span></code> trong package <strong>ISLR</strong> có sẵn trong <code class="docutils literal notranslate"><span class="pre">R</span></code> để dự
báo khách hàng nào sẽ không trả được nợ thẻ thẻ tín dụng.</p>
<p>Dữ liệu bao gồm thông tin trả nợ thẻ tín dụng của 10,000 khách hàng:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">default</span></code>: Đánh dấu khách hàng có khả năng trả nợ hay không<ul>
<li><code class="docutils literal notranslate"><span class="pre">Yes</span></code>: Không trả được nợ</li>
<li><code class="docutils literal notranslate"><span class="pre">No</span></code>: Có trả được nợ</li>
</ul>
</li>
<li><code class="docutils literal notranslate"><span class="pre">student</span></code>: Đánh dấu khách hàng là sinh viên hay không<ul>
<li><code class="docutils literal notranslate"><span class="pre">Yes</span></code>: Sinh viên</li>
<li><code class="docutils literal notranslate"><span class="pre">No</span></code>: Không phải sinh viên</li>
</ul>
</li>
<li><code class="docutils literal notranslate"><span class="pre">balance</span></code>: Trung bình dư nợ còn lại khách hàng phải trả</li>
<li><code class="docutils literal notranslate"><span class="pre">income</span></code>: Thu nhập của khách hàng</li>
</ul>
<p>Thuật toán gồm các bước sau:</p>
<ul class="simple">
<li><strong>Bước 1</strong>: Chọn biến đầu vào phân nhánh tốt nhất (best splits) để
chia dữ liệu thành 2 nhóm sao cho tính đồng nhất (the
purity/homogeneity) của outcome trong 2 nhóm là maximized (tức là
càng nhiều trường hợp khách hàng không trả được nợ vào một nhóm, và
các nhiều trường hợp khách hàng trả được nợ vào nhóm còn lại).<ul>
<li>Nếu biến đầu vào là biến liên tục (continuous), chọn một điểm
cut-off để maximize purity của 2 nhóm được tạo ra.</li>
<li>Nếu biến đầu vào là biến rời rạc (categorical), combine the
categories to obtain two groups with maximum purity.</li>
</ul>
</li>
<li><strong>Bước 2</strong>: Chia dữ liệu thành 2 nhóm nói trên và tiếp tục quá trình
cho từng nhóm con (subgroup)</li>
<li><strong>Bước 3</strong>: Lặp lại bước 1 và bước 2 cho đến khi a subgroup bao gồm
số quan sát ít hơn một số lượng nhất định mà chúng ta đặt ra hoặc
không thể phân nhóm tiếp để làm tăng tính đồng nhất</li>
</ul>
<p>The subgroups in the final set được gọi là <code class="docutils literal notranslate"><span class="pre">terminal</span> <span class="pre">nodes</span></code>. Mỗi
terminal node được phân loại vào một category of the outcome or the
other dựa vào the most frequent value of the outcome for the sample in
that node.</p>
<ul class="simple">
<li><strong>Bước 4</strong>: To classify a case, run it down the tree to a terminal
node, and assign it the modal outcome value assigned in step 3.</li>
</ul>
<p>Quá trình trên có thể dẫn đến việc cây được xây dựng rất là lớn và sẽ
dẫn đến <code class="docutils literal notranslate"><span class="pre">overfitting</span></code> (chỉ “chính xác” trên tập dữ liệu huấn luyện -
<code class="docutils literal notranslate"><span class="pre">training</span> <span class="pre">data</span></code>, nhưng thiếu “chính xác” trên tập dữ liệu kiểm tra -
<code class="docutils literal notranslate"><span class="pre">testing</span> <span class="pre">data</span></code>). Kết quả là, những quan sát mới sẽ không được phân
loại chính xác. Để khắc phục vấn đề trên chúng ta có thể dùng kỹ thuật
“tỉa” cây (<code class="docutils literal notranslate"><span class="pre">pruning</span></code>) bằng việc lựa chọn cây với 10-fold
cross-validated prediction error nhỏ nhất. Cây đã được tỉa sẽ được sử
dụng cho việc dự báo các quan sát trong tương lai.</p>
<p>Trong <code class="docutils literal notranslate"><span class="pre">R</span></code>, việc xây dựng cây quyết định (decision trees) cũng như “tỉa
cành” chúng ta có thể dùng hàm <code class="docutils literal notranslate"><span class="pre">rpart()</span></code> và <code class="docutils literal notranslate"><span class="pre">prune()</span></code> trong package
<strong>rpart</strong>.</p>
<p>Dưới đây sẽ là ví dụ về việc xây dựng cây quyết định để phân loại các
quan sát là khách hàng sử dụng thẻ tín dụng vào 2 nhóm: Trả được nợ hay
không trả được nợ.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data</span>
<span class="kn">library</span><span class="p">(</span>ISLR<span class="p">)</span>
data<span class="p">(</span><span class="s">&quot;Default&quot;</span><span class="p">)</span>

<span class="c1"># Chia dữ liệu thành 2 tập: train/test</span>
<span class="kp">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span>
train <span class="o">&lt;-</span> <span class="kp">sample</span><span class="p">(</span><span class="kp">nrow</span><span class="p">(</span>Default<span class="p">),</span> <span class="m">0.7</span><span class="o">*</span><span class="kp">nrow</span><span class="p">(</span>Default<span class="p">))</span>
df.train <span class="o">&lt;-</span> Default<span class="p">[</span>train<span class="p">,]</span>
df.validate <span class="o">&lt;-</span> Default<span class="p">[</span><span class="o">-</span>train<span class="p">,]</span>

<span class="c1"># Biến đầu ra của dữ liệu huấn luyện</span>
<span class="kp">table</span><span class="p">(</span>df.train<span class="o">$</span>default<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##</span>
<span class="c1">##   No  Yes</span>
<span class="c1">## 6765  235</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Biến đầu ra của dữ liệu kiểm tra</span>
<span class="kp">table</span><span class="p">(</span>df.validate<span class="o">$</span>default<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##</span>
<span class="c1">##   No  Yes</span>
<span class="c1">## 2902   98</span>
</pre></div>
</div>
<p>Trước tiên, chúng ta sẽ xây dựng một cây quyết định với tập dữ liệu huấn
luyện, sử dụng hàm <code class="docutils literal notranslate"><span class="pre">rpart()</span></code>.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Classical decision tree</span>
<span class="kn">library</span><span class="p">(</span>rpart<span class="p">)</span>
<span class="kp">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span>
<span class="c1"># 1. Grows the tree</span>
dtree <span class="o">&lt;-</span> rpart<span class="p">(</span>default <span class="o">~</span> <span class="m">.</span><span class="p">,</span>
               data <span class="o">=</span> df.train<span class="p">,</span>
               method <span class="o">=</span> <span class="s">&quot;class&quot;</span><span class="p">,</span>  <span class="c1"># biến đầu ra - rời rạc</span>
               parms<span class="o">=</span><span class="kt">list</span><span class="p">(</span>split<span class="o">=</span><span class="s">&quot;information&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Để xem và thống kê kết quả của mô hình vừa xây dựng, chúng ta có thể sử
dụng hàm <code class="docutils literal notranslate"><span class="pre">print()</span></code> và <code class="docutils literal notranslate"><span class="pre">summary()</span></code>. Cây quyết định có thể sẽ rất lớn
và cần phải sử dụng kỹ thuật “tỉa cành”.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kp">print</span><span class="p">(</span>dtree<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## n= 7000</span>
<span class="c1">##</span>
<span class="c1">## node), split, n, loss, yval, (yprob)</span>
<span class="c1">##       * denotes terminal node</span>
<span class="c1">##</span>
<span class="c1">##  1) root 7000 235 No (0.966428571 0.033571429)</span>
<span class="c1">##    2) balance&lt; 1472.405 6287  46 No (0.992683315 0.007316685) *</span>
<span class="c1">##    3) balance&gt;=1472.405 713 189 No (0.734922861 0.265077139)</span>
<span class="c1">##      6) balance&lt; 1800.002 501  69 No (0.862275449 0.137724551) *</span>
<span class="c1">##      7) balance&gt;=1800.002 212  92 Yes (0.433962264 0.566037736)</span>
<span class="c1">##       14) balance&lt; 1971.915 127  53 No (0.582677165 0.417322835)</span>
<span class="c1">##         28) income&lt; 31813.18 85  26 No (0.694117647 0.305882353) *</span>
<span class="c1">##         29) income&gt;=31813.18 42  15 Yes (0.357142857 0.642857143) *</span>
<span class="c1">##       15) balance&gt;=1971.915 85  18 Yes (0.211764706 0.788235294) *</span>
</pre></div>
</div>
<p>Để lựa chọn kích thước của cây, chúng ta có thể kiểm tra phần
<code class="docutils literal notranslate"><span class="pre">cptable</span></code> trong kết quả model <code class="docutils literal notranslate"><span class="pre">dtree</span></code> như sau:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data about the prediction error for various tree sizes</span>
dtree<span class="o">$</span>cptable
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##           CP nsplit rel error    xerror       xstd</span>
<span class="c1">## 1 0.05957447      0 1.0000000 1.0000000 0.06412848</span>
<span class="c1">## 2 0.05106383      3 0.7914894 0.8553191 0.05945709</span>
<span class="c1">## 3 0.01000000      4 0.7404255 0.8255319 0.05844266</span>
</pre></div>
</div>
<p>Kết quả cho chúng ta thấy thông tin về sai số dự báo đối với mỗi kích
thước khác nhau của cây.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">CP</span></code> - tham số đánh giá độ phức tạp của mô hình
(<code class="docutils literal notranslate"><span class="pre">complexity</span> <span class="pre">parameter</span></code>) dùng để penalize larger trees</li>
<li><code class="docutils literal notranslate"><span class="pre">nsplit</span></code> - số lần phân nhóm (<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">branch</span> <span class="pre">splits</span></code>) mô tả
kích thước của cây. Một cây với n splits sẽ có n+1 terminal nodes</li>
<li><code class="docutils literal notranslate"><span class="pre">rel</span> <span class="pre">error</span></code> - tỷ lệ sai số (<code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">rate</span></code>) của cây đối với từng
kích thước được xác định trên tập dữ liệu training.</li>
<li><code class="docutils literal notranslate"><span class="pre">xerror</span></code> - cross-validated error dựa trên 10-fold cross validation
(cũng dựa trên dữ liệu training)</li>
<li><code class="docutils literal notranslate"><span class="pre">xstd</span></code> - sai số chuẩn (standard error) của cross validation error</li>
</ul>
<p>Chúng ta có thể sử dụng hàm <code class="docutils literal notranslate"><span class="pre">plotcp()</span></code> để xem mối quan hệ giữa
cross-validated error (<code class="docutils literal notranslate"><span class="pre">xerror</span></code>) và tham số complexity (<code class="docutils literal notranslate"><span class="pre">CP</span></code>). Một
sự lựa chọn tốt cho kích thước của cây là cây nhỏ nhất mà
cross-validated error nằm trong khoảng giá trị 1 standard error của
cross-validated error nhỏ nhất</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the cross-validated error against the complexity parameter</span>
plotcp<span class="p">(</span>dtree<span class="p">)</span>
</pre></div>
</div>
<p><img alt="image5" src="p03-04-decision-tree_files/figure-html/unnamed-chunk-9-1.png" /></p>
<p>Trong trường hợp này, min xerror là 0.8255319 và tương ứng với xstd =
0.058442666, như vậy cây nhỏ nhất với xerror nằm trong khoảng giá trị
(0.8255319-0.058442666, 0.8255319+0.058442666), hay (0.7670892,
0.8839746). Xem bảng kết quả <code class="docutils literal notranslate"><span class="pre">cptable</span></code> có thể thấy cây với 3 splits
(xerror = 0.8553191, CP = 0.05106383) thỏa mãn điều kiện nói trên.</p>
<p>Còn nếu dựa vào plot mối quan hệ giữa xerror và CP, chúng ta sẽ lựa chọn
cây với giá trị CP ngoài cùng bên trái (CP cao nhất) nằm dưới đường
line. Nếu nhìn vào plot này chúng ta có thể chọn CP = 0.055 để tiến hành
“tỉa” cây.</p>
<p>Như vậy, trong trường hợp này, để “tỉa” cây chúng ta có thể lựa chọn CP
= 0.051 hoặc CP = 0.055 (chênh lệch không đáng kể), nên chúng ta sẽ ưu
tiên lựa chọn cây với ít “phức tạp” (ít split) hơn - trường hợp này lựa
chọn cây với 3 splits (4 terminal nodes).</p>
<p>Hàm <code class="docutils literal notranslate"><span class="pre">prune()</span></code> sử dụng tham số complexity để tỉa cây theo kích thước
mong muốn. Cụ thể hơn, cách này sẽ cắt bỏ đi các splits mà ít quan trọng
nhất của cây theo giá trị của tham số complexity mà chúng ta mong muốn.</p>
<p>Trong trường hợp này, chúng ta lựa chọn cây với 3 splits, tương ứng với
complexity (CP = ), do đó để lựa chọn cây với kích thước mong muốn,
chúng ta sử dụng câu lệnh sau:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2. Prunes the tree</span>
dtree.pruned <span class="o">&lt;-</span> prune<span class="p">(</span>dtree<span class="p">,</span> cp <span class="o">=</span> <span class="m">0.05106383</span><span class="p">)</span>

<span class="kp">print</span><span class="p">(</span>dtree.pruned<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## n= 7000</span>
<span class="c1">##</span>
<span class="c1">## node), split, n, loss, yval, (yprob)</span>
<span class="c1">##       * denotes terminal node</span>
<span class="c1">##</span>
<span class="c1">##  1) root 7000 235 No (0.966428571 0.033571429)</span>
<span class="c1">##    2) balance&lt; 1472.405 6287  46 No (0.992683315 0.007316685) *</span>
<span class="c1">##    3) balance&gt;=1472.405 713 189 No (0.734922861 0.265077139)</span>
<span class="c1">##      6) balance&lt; 1800.002 501  69 No (0.862275449 0.137724551) *</span>
<span class="c1">##      7) balance&gt;=1800.002 212  92 Yes (0.433962264 0.566037736)</span>
<span class="c1">##       14) balance&lt; 1971.915 127  53 No (0.582677165 0.417322835) *</span>
<span class="c1">##       15) balance&gt;=1971.915 85  18 Yes (0.211764706 0.788235294) *</span>
</pre></div>
</div>
<p>Hàm <code class="docutils literal notranslate"><span class="pre">prp()</span></code> trong package <strong>rpart.plot</strong> sử dụng để trực quan hóa cây
quyết định cuối cùng. Để phân loại một quan sát, bắt đầu từ phần đỉnh
của cây, sau đó di chuyển sang nhánh bên trái nếu một điều kiện là đúng
hoặc sang phải trường hợp ngược lại. Tiếp tục di chuyển xuống phía dưới
cho đến khi gặp terminal node (lá), tức đã được phân loại.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kn">library</span><span class="p">(</span>rpart.plot<span class="p">)</span>
prp<span class="p">(</span>dtree.pruned<span class="p">,</span>
    type <span class="o">=</span> <span class="m">2</span><span class="p">,</span> <span class="c1"># Draws the split labels below each node</span>
    extra <span class="o">=</span> <span class="m">104</span><span class="p">,</span> <span class="c1"># Includes the probabilities for each class, along with the percentage of observations in each node</span>
    fallen.leaves <span class="o">=</span> <span class="bp">T</span><span class="p">,</span> <span class="c1"># Displays the terminal nodes at the bottom of the graph</span>
    main <span class="o">=</span> <span class="s">&quot;Decision Tree&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
<p><img alt="image6" src="p03-04-decision-tree_files/figure-html/unnamed-chunk-11-1.png" /></p>
<p>Cách đọc kết quả từ cây quyết định từ trên xuống dưới như sau:</p>
<ul class="simple">
<li>Tập dữ liệu huấn luyện ban đầu của chúng ta (tức bao gồm tất cả quan
sát - 100%) có 97% là <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code> (khách hàng trả được nợ), 3%
là <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">Yes</span></code> (không trả được nợ)</li>
<li>Với điều kiện phân nhánh đầu tiên <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1472</span></code> (tức dư nợ còn
lại phải trả &lt; 1472):<ul>
<li>90% khách hàng thỏa mãn điều kiện <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1472</span></code> (sẽ được phân
loại về nhóm <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code> - trả được nợ), trong đó :<ul>
<li>99% là <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code> (trả được nợ)</li>
<li>1% là <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">Yes</span></code> (không trả được nợ)</li>
</ul>
</li>
<li>10% khách hàng không thỏa mãn điều kiện <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1472</span></code>, trong
đó:<ul>
<li>73% là <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code> (trả được nợ)</li>
<li>27% là <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">Yes</span></code> (không trả được nợ)</li>
</ul>
</li>
</ul>
</li>
<li>Sau đó, đối với 10% khách hàng không thỏa mãn điều kiện
<code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1472</span></code> lại được tiếp tục phân nhánh nhỏ hơn với các điều
kiện phân nhánh: <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1800</span></code> và <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1972</span></code> (tương tự
cách giải thích như trên)</li>
</ul>
<p>…</p>
<ul class="simple">
<li>Kết quả cuối cùng, các quan sát trong tập training được chia thành 4
vùng:<ul>
<li><strong>R1</strong>: <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1472</span></code> -&gt; thuộc về nhóm <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code></li>
<li><strong>R2</strong>: <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&gt;=</span> <span class="pre">1472</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1800</span></code> -&gt; thuộc về nhóm
<code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code></li>
<li><strong>R3</strong>: <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&gt;=</span> <span class="pre">1800</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&lt;</span> <span class="pre">1972</span></code> -&gt; thuộc về nhóm
<code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code></li>
<li><strong>R4</strong>: <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">&gt;=</span> <span class="pre">1972</span></code> -&gt; thuộc về nhóm <code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">Yes</span></code></li>
</ul>
</li>
</ul>
<p>Và sau khi đã build được mô hình cây quyết định hoàn chỉnh, chúng ta sẽ
phân loại những quan sát mới - tập dữ liệu validation bằng việc sử dụng
hàm <code class="docutils literal notranslate"><span class="pre">predict()</span></code>, sau đó só sánh kết quả dự báo và thực tế như sau:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Phân loại những quan sát mới</span>
dtree.pred <span class="o">&lt;-</span> predict<span class="p">(</span>dtree.pruned<span class="p">,</span>
                      df.validate<span class="p">,</span>
                      type <span class="o">=</span> <span class="s">&quot;class&quot;</span>
                      <span class="p">)</span>

<span class="c1"># So sánh kết quả dự báo và thực tế</span>
dtree.perf <span class="o">&lt;-</span> <span class="kp">table</span><span class="p">(</span>df.validate<span class="o">$</span>default<span class="p">,</span>
                    dtree.pred<span class="p">,</span>
                    dnn <span class="o">=</span> <span class="kt">c</span><span class="p">(</span><span class="s">&quot;Actual&quot;</span><span class="p">,</span> <span class="s">&quot;Predicted&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
dtree.perf
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##       Predicted</span>
<span class="c1">## Actual   No  Yes</span>
<span class="c1">##    No  2892   10</span>
<span class="c1">##    Yes   75   23</span>
</pre></div>
</div>
<p>Kết quả cho chúng ta thấy trong số 3000 quan sát của tập dữ liệu kiểm
tra (quan sát mới) có 2892 khách hàng trả được nợ (<code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">No</span></code>) và
23 khách hàng không trả được nợ (<code class="docutils literal notranslate"><span class="pre">default</span> <span class="pre">=</span> <span class="pre">Yes</span></code>) được dự báo đúng.
Như vậy, tổng số quan sát được dự báo đúng là 2915 (2892+23), tức tỷ lệ
quan sát dự báo đúng (<code class="docutils literal notranslate"><span class="pre">accuracy</span></code>) là 97% (2915/3000). Lưu ý rằng
phương pháp cây quyết định có thể bị biased đối với những biến đầu vào
có nhiều giá trị hoặc nhiều giá trị bị missing.</p>
<p><strong>Mô hình cây và mô hình tuyến tính</strong></p>
<p>Mô hình cây quyết định là một cách tiếp cận khác so với mô hình tuyết
tính, cụ thể là hồi quy tuyến tính có dạng:</p>
<div class="math notranslate">
\[f(X) = \beta_0 + \sum_{j=1}^{P}X_jB_j\]</div>
<p>Như vậy, câu hỏi đặt ra là mô hình nào tốt hơn? Câu trả lời là: Tùy
thuộc vào bài toán mà chúng ta muốn giải quyết là gì. Nếu bài toán chúng
ta muốn giải quyết bao gồm biến đầu ra và các biến đầu vào có mối quan
hệ gần giống với tuyến tính thì chúng ta nên sử dụng hồi quy tuyến tính.
Còn nếu giữa các biến đầu vào và biến đầu ra có mối quan hệ phi tuyến
tính hoặc phức tạp thì chúng ta nên sử dụng mô hình cây quyết định. Để
đánh giá chất lượng dự báo của mô hình cây quyết định và mô hình tuyến
tính, chúng ta có thể tính toán sai số trên tập dữ liệu validation hoặc
tính toán sai số sử dụng cross-validation.</p>
<p><strong>Ưu điểm và nhược điểm của mô hình cây quyết định</strong></p>
<p>Mô hình cây quyết định có những <strong>ưu điểm</strong> vượt trội so với mô hình
tuyến tính như sau: Thứ nhất, mô hình cây quyết định có thể mô tả bằng
graphic, vì vậy rất dễ dàng diễn giải kết quả mô hình, thậm chí là dễ
dàng hơn so với mô hình tuyến tính. Thứ hai, mô hình cây quyết định có
thể sử dụng với những biến đầu vào là biến rời rạc mà không cần phải
biến đổi về dạng dummy (0-1). Tuy nhiên, <strong>nhược điểm</strong> của mô hình cây
quyết định là thiếu ổn định (<code class="docutils literal notranslate"><span class="pre">non-robust</span></code>). Hay nói cách khác, với một
sự thay đổi nhỏ trong tập dữ liệu, có thể dẫn đến sự thay đổi lớn trong
kết quả dự báo.</p>
<p>Tuy nhiên, những phương pháp mà tổng hợp nhiều cây quyết định như:
<code class="docutils literal notranslate"><span class="pre">bagging</span></code>, <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forests</span></code>, <code class="docutils literal notranslate"><span class="pre">boosting</span></code> có thể khắc phục được
nhược điểm nêu trên và cải thiện chất lượng dự báo. Chúng ta sẽ cùng tìm
hiểu trong các phần tiếp theo.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="p03-05-bagging-boosting.html" class="btn btn-neutral float-right" title="5. Bagging, RandomForest và Boosting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="p03-03-logistic-regression.html" class="btn btn-neutral float-left" title="3. Mô hình hồi quy logistic" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Anh Hoang Duc

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>