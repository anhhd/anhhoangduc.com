[
["xay-dng-mo-hinh-vi-h2o.html", "Chương 20 Xây dựng mô hình với H2O 20.1 Giới thiệu 20.2 Cài đặt và khởi động 20.3 Thực hành với R 20.4 Tài liệu tham khảo", " Chương 20 Xây dựng mô hình với H2O 20.1 Giới thiệu H2O là một phần mềm dựa trên nền tảng của Java dùng để mô hình hóa dữ liệu (data modeling) và tính toán nói chung (general computing). H2O là một platform mã nguồn mở hàng đầu thế giới hiện nay về Machine Learning và AI. Hỗ trợ nhiều phần mềm khác nhau như: R, Python, Azure, Spark… 20.2 Cài đặt và khởi động Để cài đặt và khởi động H2O, chúng ta cần thực hiện các bước sau: Bước 1: Cài đặt Java Bước 2: Cài đặt R package h2o install.packages(&quot;h2o&quot;) Bước 3: Khởi động H2O từ R - sử dụng câu lệnh h2o.init() library(h2o) h2o.init(ip = &quot;localhost&quot;, port = 54321, nthreads= -1, max_mem_size = &quot;4g&quot;) # Đặt mức RAM tối đa Lưu ý: Trong trường hợp chúng ta muốn tắt H2O trên R, chúng ta có thể sử dụng câu lệnh sau: h2o.shutdown(prompt = T) 20.3 Thực hành với R Để thực hành xây dựng mô hình dự báo với H2O, chúng ta sẽ sử dụng dữ liệu có sẵn trong R - GermanCredit trong package caret. Đây là dữ liệu ghi nhận về lịch sử vay của khách hàng, với các 61 biến đầu vào cùng với biến đầu ra Class ghi nhận thực tế là các khoản vay đó có phải là khoản nợ xấu hay không. Chúng ta sẽ dự báo khoản vay nào không có nợ xấu. 20.3.1 Lấy dữ liệu # Bước 1: Lấy dữ liệu library(caret) data(&quot;GermanCredit&quot;) 20.3.2 Kiểm tra dữ liệu # Bước 2: Kiểm tra dữ liệu # Kiểm tra định dạng các biến trong tập dữ liệu library(dplyr) GermanCredit %&gt;% str ## &#39;data.frame&#39;: 1000 obs. of 62 variables: ## $ Duration : int 6 48 12 42 24 36 24 36 12 30 ... ## $ Amount : int 1169 5951 2096 7882 4870 9055 2835 6948 3059 5234 ... ## $ InstallmentRatePercentage : int 4 2 2 2 3 2 3 2 2 4 ... ## $ ResidenceDuration : int 4 2 3 4 4 4 4 2 4 2 ... ## $ Age : int 67 22 49 45 53 35 53 35 61 28 ... ## $ NumberExistingCredits : int 2 1 1 1 2 1 1 1 1 2 ... ## $ NumberPeopleMaintenance : int 1 1 2 2 2 2 1 1 1 1 ... ## $ Telephone : num 0 1 1 1 1 0 1 0 1 1 ... ## $ ForeignWorker : num 1 1 1 1 1 1 1 1 1 1 ... ## $ Class : Factor w/ 2 levels &quot;Bad&quot;,&quot;Good&quot;: 2 1 2 2 1 2 2 2 2 1 ... ## $ CheckingAccountStatus.lt.0 : num 1 0 0 1 1 0 0 0 0 0 ... ## $ CheckingAccountStatus.0.to.200 : num 0 1 0 0 0 0 0 1 0 1 ... ## $ CheckingAccountStatus.gt.200 : num 0 0 0 0 0 0 0 0 0 0 ... ## $ CheckingAccountStatus.none : num 0 0 1 0 0 1 1 0 1 0 ... ## $ CreditHistory.NoCredit.AllPaid : num 0 0 0 0 0 0 0 0 0 0 ... ## $ CreditHistory.ThisBank.AllPaid : num 0 0 0 0 0 0 0 0 0 0 ... ## $ CreditHistory.PaidDuly : num 0 1 0 1 0 1 1 1 1 0 ... ## $ CreditHistory.Delay : num 0 0 0 0 1 0 0 0 0 0 ... ## $ CreditHistory.Critical : num 1 0 1 0 0 0 0 0 0 1 ... ## $ Purpose.NewCar : num 0 0 0 0 1 0 0 0 0 1 ... ## $ Purpose.UsedCar : num 0 0 0 0 0 0 0 1 0 0 ... ## $ Purpose.Furniture.Equipment : num 0 0 0 1 0 0 1 0 0 0 ... ## $ Purpose.Radio.Television : num 1 1 0 0 0 0 0 0 1 0 ... ## $ Purpose.DomesticAppliance : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Purpose.Repairs : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Purpose.Education : num 0 0 1 0 0 1 0 0 0 0 ... ## $ Purpose.Vacation : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Purpose.Retraining : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Purpose.Business : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Purpose.Other : num 0 0 0 0 0 0 0 0 0 0 ... ## $ SavingsAccountBonds.lt.100 : num 0 1 1 1 1 0 0 1 0 1 ... ## $ SavingsAccountBonds.100.to.500 : num 0 0 0 0 0 0 0 0 0 0 ... ## $ SavingsAccountBonds.500.to.1000 : num 0 0 0 0 0 0 1 0 0 0 ... ## $ SavingsAccountBonds.gt.1000 : num 0 0 0 0 0 0 0 0 1 0 ... ## $ SavingsAccountBonds.Unknown : num 1 0 0 0 0 1 0 0 0 0 ... ## $ EmploymentDuration.lt.1 : num 0 0 0 0 0 0 0 0 0 0 ... ## $ EmploymentDuration.1.to.4 : num 0 1 0 0 1 1 0 1 0 0 ... ## $ EmploymentDuration.4.to.7 : num 0 0 1 1 0 0 0 0 1 0 ... ## $ EmploymentDuration.gt.7 : num 1 0 0 0 0 0 1 0 0 0 ... ## $ EmploymentDuration.Unemployed : num 0 0 0 0 0 0 0 0 0 1 ... ## $ Personal.Male.Divorced.Seperated : num 0 0 0 0 0 0 0 0 1 0 ... ## $ Personal.Female.NotSingle : num 0 1 0 0 0 0 0 0 0 0 ... ## $ Personal.Male.Single : num 1 0 1 1 1 1 1 1 0 0 ... ## $ Personal.Male.Married.Widowed : num 0 0 0 0 0 0 0 0 0 1 ... ## $ Personal.Female.Single : num 0 0 0 0 0 0 0 0 0 0 ... ## $ OtherDebtorsGuarantors.None : num 1 1 1 0 1 1 1 1 1 1 ... ## $ OtherDebtorsGuarantors.CoApplicant : num 0 0 0 0 0 0 0 0 0 0 ... ## $ OtherDebtorsGuarantors.Guarantor : num 0 0 0 1 0 0 0 0 0 0 ... ## $ Property.RealEstate : num 1 1 1 0 0 0 0 0 1 0 ... ## $ Property.Insurance : num 0 0 0 1 0 0 1 0 0 0 ... ## $ Property.CarOther : num 0 0 0 0 0 0 0 1 0 1 ... ## $ Property.Unknown : num 0 0 0 0 1 1 0 0 0 0 ... ## $ OtherInstallmentPlans.Bank : num 0 0 0 0 0 0 0 0 0 0 ... ## $ OtherInstallmentPlans.Stores : num 0 0 0 0 0 0 0 0 0 0 ... ## $ OtherInstallmentPlans.None : num 1 1 1 1 1 1 1 1 1 1 ... ## $ Housing.Rent : num 0 0 0 0 0 0 0 1 0 0 ... ## $ Housing.Own : num 1 1 1 0 0 0 1 0 1 1 ... ## $ Housing.ForFree : num 0 0 0 1 1 1 0 0 0 0 ... ## $ Job.UnemployedUnskilled : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Job.UnskilledResident : num 0 0 1 0 0 1 0 0 1 0 ... ## $ Job.SkilledEmployee : num 1 1 0 1 1 0 1 0 0 0 ... ## $ Job.Management.SelfEmp.HighlyQualified: num 0 0 0 0 0 0 0 1 0 1 ... # Kiểm tra biến đầu ra (biến muốn dự báo) GermanCredit$Class %&gt;% table %&gt;% prop.table ## . ## Bad Good ## 0.3 0.7 Như vậy, chúng ta thấy trong tập dữ liệu này: 70% là các khoản vay không có nợ xấu 30% là các khoản vay có nợ xấu 20.3.3 Khởi động H2O # Bước 3: Khởi động H2O library(h2o) h2o.init(ip = &quot;localhost&quot;, port = 54321, nthreads= -1, max_mem_size = &quot;4g&quot;) # Đặt mức RAM tối đa ## ## H2O is not running yet, starting it now... ## ## Note: In case of errors look at the following log files: ## C:\\Users\\Admin\\AppData\\Local\\Temp\\RtmpWgKGh5/h2o_Admin_started_from_r.out ## C:\\Users\\Admin\\AppData\\Local\\Temp\\RtmpWgKGh5/h2o_Admin_started_from_r.err ## ## ## Starting H2O JVM and connecting: . Connection successful! ## ## R is connected to the H2O cluster: ## H2O cluster uptime: 13 seconds 619 milliseconds ## H2O cluster timezone: Asia/Bangkok ## H2O data parsing timezone: UTC ## H2O cluster version: 3.20.0.2 ## H2O cluster version age: 1 year, 3 months and 14 days !!! ## H2O cluster name: H2O_started_from_R_Admin_lth831 ## H2O cluster total nodes: 1 ## H2O cluster total memory: 3.56 GB ## H2O cluster total cores: 4 ## H2O cluster allowed cores: 4 ## H2O cluster healthy: TRUE ## H2O Connection ip: localhost ## H2O Connection port: 54321 ## H2O Connection proxy: NA ## H2O Internal Security: FALSE ## H2O API Extensions: Algos, AutoML, Core V3, Core V4 ## R Version: R version 3.4.0 (2017-04-21) 20.3.4 Đưa dữ liệu vào H2O Để đưa dữ liệu vào H2O, chúng ta sử dụng câu lệnh: as.h2o(). # Bước 4: Đưa dữ liệu vào h2o data_h2o &lt;- as.h2o(GermanCredit) ## | | | 0% | |=================================================================| 100% 20.3.5 Chia dữ liệu train/test Chia tập dữ liệu thành 2 tập dữ liệu train và test (tỷ lệ 80-20) # Bước 5: Chia tập dữ liệu thành: train/test (tỷ lệ 80/20) set.seed(1234) data_split = h2o.splitFrame(data = data_h2o, ratios = 0.8) train = data_split[[1]] test = data_split[[2]] # Tập dữ liệu train (data frame) train_df &lt;- as.data.frame(train) train_df$Class %&gt;% table ## . ## Bad Good ## 235 551 # Tập dữ liệu test (data frame) test_df &lt;- as.data.frame(test) test_df$Class %&gt;% table ## . ## Bad Good ## 65 149 20.3.6 Xây dựng mô hình trên tập train Để xây dựng mô hình dự báo với H2O, chúng ta có thể sử dụng những câu lệnh khác nhau tương ứng với từng phương pháp/thuật toán như: Logistic regression, Random Forests, Boosting… h2o.glm() - Logistic regression h2o.randomForest() - Random Forests h2o.gbm() - Boosting # Bước 6: Xây dựng mô hình trên train start_time &lt;- Sys.time() set.seed(1) gbm_model1 &lt;- h2o.gbm(training_frame = train, # Tập dữ liệu train x = setdiff(names(GermanCredit), &quot;Class&quot;), # Các biến đầu vào y = &quot;Class&quot; # Biến đầu ra (biến muốn dự báo) ) ## | | | 0% | |============= | 20% | |=========================================== | 66% | |=================================================================| 100% end_time &lt;- Sys.time() time &lt;- end_time - start_time time ## Time difference of 4.30056 secs Chúng ta thấy việc xây dựng mô hình với H2O có tốc độ rất nhanh, xây dựng mô hình với các tham số cơ bản với dữ liệu này chỉ mất khoảng 4.3 giây. Đương nhiên trong trường hợp này dữ liệu nhỏ nên chúng ta chưa nhìn thấy rõ ưu điểm vượt trội của H2O về tốc độ, nhưng trong trường hơp dữ liệu lớn, việc sử dụng H2O sẽ rút ngắn thời gian xây dựng mô hình dự báo của chúng ta đi rất nhiều. # Summary model gbm_model1 %&gt;% summary ## Model Details: ## ============== ## ## H2OBinomialModel: gbm ## Model Key: GBM_model_R_1569766512944_1 ## Model Summary: ## number_of_trees number_of_internal_trees model_size_in_bytes min_depth ## 1 50 50 14178 5 ## max_depth mean_depth min_leaves max_leaves mean_leaves ## 1 5 5.00000 9 26 17.58000 ## ## H2OBinomialMetrics: gbm ## ** Reported on training data. ** ## ## MSE: 0.07258735 ## RMSE: 0.2694204 ## LogLoss: 0.2676266 ## Mean Per-Class Error: 0.07134031 ## AUC: 0.9794455 ## Gini: 0.958891 ## ## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold: ## Bad Good Error Rate ## Bad 210 25 0.106383 =25/235 ## Good 20 531 0.036298 =20/551 ## Totals 230 556 0.057252 =45/786 ## ## Maximum Metrics: Maximum metrics at their respective thresholds ## metric threshold value idx ## 1 max f1 0.585928 0.959350 231 ## 2 max f2 0.528659 0.973467 251 ## 3 max f0point5 0.641146 0.964326 215 ## 4 max accuracy 0.585928 0.942748 231 ## 5 max precision 0.985738 1.000000 0 ## 6 max recall 0.301839 1.000000 324 ## 7 max specificity 0.985738 1.000000 0 ## 8 max absolute_mcc 0.585928 0.862683 231 ## 9 max min_per_class_accuracy 0.650274 0.932849 211 ## 10 max mean_per_class_accuracy 0.641146 0.936919 215 ## ## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)` ## ## ## ## Scoring History: ## timestamp duration number_of_trees training_rmse ## 1 2019-09-29 21:15:33 0.124 sec 0 0.45781 ## 2 2019-09-29 21:15:34 0.712 sec 1 0.44489 ## 3 2019-09-29 21:15:34 0.812 sec 2 0.43324 ## 4 2019-09-29 21:15:34 0.876 sec 3 0.42313 ## 5 2019-09-29 21:15:34 0.956 sec 4 0.41501 ## training_logloss training_auc training_lift ## 1 0.61000 0.50000 1.00000 ## 2 0.58254 0.82314 1.42650 ## 3 0.55877 0.83729 1.42650 ## 4 0.53861 0.85373 1.42650 ## 5 0.52240 0.86354 1.42650 ## training_classification_error ## 1 0.29898 ## 2 0.22774 ## 3 0.21374 ## 4 0.20738 ## 5 0.19338 ## ## --- ## timestamp duration number_of_trees training_rmse ## 46 2019-09-29 21:15:36 2.757 sec 45 0.27706 ## 47 2019-09-29 21:15:36 2.789 sec 46 0.27555 ## 48 2019-09-29 21:15:36 2.829 sec 47 0.27383 ## 49 2019-09-29 21:15:36 2.853 sec 48 0.27225 ## 50 2019-09-29 21:15:36 2.889 sec 49 0.27105 ## 51 2019-09-29 21:15:36 2.921 sec 50 0.26942 ## training_logloss training_auc training_lift ## 46 0.27988 0.97668 1.42650 ## 47 0.27727 0.97715 1.42650 ## 48 0.27464 0.97787 1.42650 ## 49 0.27199 0.97879 1.42650 ## 50 0.27012 0.97924 1.42650 ## 51 0.26763 0.97945 1.42650 ## training_classification_error ## 46 0.06234 ## 47 0.06107 ## 48 0.05980 ## 49 0.05980 ## 50 0.05852 ## 51 0.05725 ## ## Variable Importances: (Extract with `h2o.varimp`) ## ================================================= ## ## Variable Importances: ## variable relative_importance scaled_importance ## 1 CheckingAccountStatus.none 84.350624 1.000000 ## 2 Amount 82.419136 0.977102 ## 3 Duration 68.733696 0.814857 ## 4 Age 31.725632 0.376116 ## 5 Purpose.NewCar 19.282278 0.228597 ## percentage ## 1 0.156410 ## 2 0.152829 ## 3 0.127452 ## 4 0.058828 ## 5 0.035755 ## ## --- ## variable relative_importance scaled_importance ## 54 Housing.ForFree 0.132180 0.001567 ## 55 Purpose.DomesticAppliance 0.000000 0.000000 ## 56 Purpose.Retraining 0.000000 0.000000 ## 57 Purpose.Other 0.000000 0.000000 ## 58 Personal.Male.Divorced.Seperated 0.000000 0.000000 ## 59 Job.UnemployedUnskilled 0.000000 0.000000 ## percentage ## 54 0.000245 ## 55 0.000000 ## 56 0.000000 ## 57 0.000000 ## 58 0.000000 ## 59 0.000000 Nhìn vào kết quả mô hình vừa được xây dựng trên tập train, chúng ta có thể thấy một số thông tin quan trọng sau: Các tham số (parameters) cơ bản của mô hình: number_of_trees = 50: Số lượng cây là 50 max_depth = 5: Mỗi cây có 5 tầng (mức độ phức tạp của mô hình) AUC trên tập train: 0.9794455 Dựa vào mục Confusion Matrix (tối ưu hóa F1-score) có thể tính toán được: error rate (tỷ lệ quan sát dự báo sai): 45/786 = 0.057 (5.7%) accuracy (tỷ lệ quan sát dự báo đúng): 1 - 0.057 = 0.943 (94.3%) precision: 531/551 = 0.96 (96%) recall: 531/556 = 0.96 (96%) Dựa vào mục Maximum Metrics, chúng ta có thể biết được các ngưỡng cutoff xác suất để tối ưu hóa các chỉ số như accuracy, precision, recall, f1-score… max f1: Điểm cutoff xác suất là 0.585928 max accuracy: 0.585928 max recall: 0.301839 max precision: 0.985738 Dựa vào mục Variable Importances, chúng ta có thể biết được những biến nào có ảnh hưởng nhiều nhất đến biến đầu ra mà chúng ta muốn dự báo (có thể sử dụng câu lệnh h2o.varimp() để xem chi tiết). Trong trường hợp này, các biến có ảnh hưởng nhiều nhất tới biến Class theo thứ tự là: CheckingAccountStatus.none Amount Duration Age Purpose.NewCar # Kiểm tra chi tiết các biến có ảnh hướng nhiều tới biến dự báo trong mô hình gbm_model1 %&gt;% h2o.varimp() %&gt;% as.data.frame %&gt;% knitr::kable() variable relative_importance scaled_importance percentage CheckingAccountStatus.none 84.3506241 1.0000000 0.1564102 Amount 82.4191360 0.9771017 0.1528287 Duration 68.7336960 0.8148570 0.1274520 Age 31.7256317 0.3761161 0.0588284 Purpose.NewCar 19.2822781 0.2285967 0.0357549 InstallmentRatePercentage 15.5161829 0.1839486 0.0287714 OtherInstallmentPlans.None 15.2438316 0.1807198 0.0282664 CreditHistory.Critical 14.5524130 0.1725229 0.0269843 CheckingAccountStatus.lt.0 12.5769672 0.1491034 0.0233213 Property.RealEstate 12.3567972 0.1464933 0.0229130 SavingsAccountBonds.lt.100 10.7499561 0.1274437 0.0199335 OtherDebtorsGuarantors.Guarantor 9.6545200 0.1144570 0.0179022 Property.Insurance 9.3979931 0.1114158 0.0174266 Job.SkilledEmployee 8.7692375 0.1039617 0.0162607 CheckingAccountStatus.gt.200 8.7212677 0.1033930 0.0161717 ResidenceDuration 8.4237700 0.0998661 0.0156201 OtherDebtorsGuarantors.None 7.9725552 0.0945168 0.0147834 OtherInstallmentPlans.Bank 7.7707009 0.0921238 0.0144091 CreditHistory.NoCredit.AllPaid 7.2156229 0.0855432 0.0133798 Personal.Male.Single 7.0852146 0.0839972 0.0131380 NumberExistingCredits 6.5925212 0.0781562 0.0122244 Purpose.UsedCar 6.2361321 0.0739311 0.0115636 Personal.Female.NotSingle 5.6832266 0.0673762 0.0105383 EmploymentDuration.lt.1 5.2887440 0.0626995 0.0098068 EmploymentDuration.4.to.7 5.2262311 0.0619584 0.0096909 Telephone 5.1227264 0.0607313 0.0094990 Property.Unknown 4.8568892 0.0575798 0.0090061 Housing.Rent 4.7812662 0.0566832 0.0088658 CreditHistory.Delay 4.5384483 0.0538046 0.0084156 SavingsAccountBonds.Unknown 3.7545331 0.0445110 0.0069620 EmploymentDuration.1.to.4 3.6860566 0.0436992 0.0068350 Job.Management.SelfEmp.HighlyQualified 3.5472615 0.0420538 0.0065776 Purpose.Education 3.3089063 0.0392280 0.0061357 EmploymentDuration.gt.7 3.2702508 0.0387697 0.0060640 Housing.Own 3.0387659 0.0360254 0.0056347 CreditHistory.PaidDuly 2.8158870 0.0333831 0.0052215 OtherDebtorsGuarantors.CoApplicant 2.5130854 0.0297933 0.0046600 NumberPeopleMaintenance 2.4034374 0.0284934 0.0044567 CreditHistory.ThisBank.AllPaid 2.3900807 0.0283351 0.0044319 CheckingAccountStatus.0.to.200 2.0607431 0.0244307 0.0038212 Purpose.Radio.Television 2.0184691 0.0239295 0.0037428 Property.CarOther 1.9168139 0.0227244 0.0035543 Purpose.Furniture.Equipment 1.8031244 0.0213765 0.0033435 Purpose.Business 1.5692081 0.0186034 0.0029098 SavingsAccountBonds.gt.1000 1.4338670 0.0169989 0.0026588 EmploymentDuration.Unemployed 1.3670616 0.0162069 0.0025349 Purpose.Repairs 1.2434046 0.0147409 0.0023056 SavingsAccountBonds.100.to.500 1.1172017 0.0132447 0.0020716 OtherInstallmentPlans.Stores 1.0155718 0.0120399 0.0018832 SavingsAccountBonds.500.to.1000 0.7910167 0.0093777 0.0014668 ForeignWorker 0.5909842 0.0070063 0.0010959 Job.UnskilledResident 0.3838074 0.0045501 0.0007117 Personal.Male.Married.Widowed 0.2746936 0.0032566 0.0005094 Housing.ForFree 0.1321795 0.0015670 0.0002451 Purpose.DomesticAppliance 0.0000000 0.0000000 0.0000000 Purpose.Retraining 0.0000000 0.0000000 0.0000000 Purpose.Other 0.0000000 0.0000000 0.0000000 Personal.Male.Divorced.Seperated 0.0000000 0.0000000 0.0000000 Job.UnemployedUnskilled 0.0000000 0.0000000 0.0000000 20.3.7 Dự báo trên tập test # Bước 7: Dự báo trên tập test pred_test1 &lt;- h2o.predict(gbm_model1, newdata = test) %&gt;% as.data.frame() ## | | | 0% | |=================================================================| 100% pred_test1 %&gt;% head ## predict Bad Good ## 1 Bad 0.71166405 0.2883359 ## 2 Bad 0.82454629 0.1754537 ## 3 Bad 0.49154935 0.5084507 ## 4 Bad 0.79388195 0.2061180 ## 5 Good 0.03446872 0.9655313 ## 6 Bad 0.76942563 0.2305744 Nhìn vào kết quả trên, ta có thể biết được những thông tin sau: Cột predict: Là Class của khoản vay được dự báo Good: Khoản vay không phải là khoản nợ xấu Bad: Khoản vay là khoản nợ xấu Bad: Xác suất khoản vay là khoản nợ xấu Good: Xác suất khoản vay là khoản không có nợ xấu 20.3.8 Đánh giá chất lượng dự báo trên test # Bước 8: Đánh giá chất lượng dự báo trên test # Confusion matrix table(as.vector(pred_test1$predict), test_df$Class, dnn = c(&quot;Predicted&quot;, &quot;Actual&quot;) ) ## Actual ## Predicted Bad Good ## Bad 40 30 ## Good 25 119 Dựa vào confusion matrix trên tập test, chúng ta có thể tính toán được: Accuracy: (40+119)/214 = 0.74 (74%) Error rate: (25+30)/186 = 1 - 0.74 = 0.26 (26%) Precision: 119/(119+25) = 0.83 (83%) Recall: 119/(119+30) = 0.80 (80%) Note: Với H2O, chúng ta hoàn toàn có thể xây dựng mô hình trên tập train, rồi sau đó đánh giá chất lượng trên tập train và test đồng thời bằng một câu lệnh sau: set.seed(2) gbm_model2 &lt;- h2o.gbm(training_frame = train, # Xây dựng trên train x = setdiff(names(GermanCredit), &quot;Class&quot;), # Các biến đầu vào y = &quot;Class&quot;, # Biến đầu ra (biến muốn dự báo) validation_frame = test # Đánh giá trên test ) ## | | | 0% | |======================================= | 60% | |=================================================================| 100% gbm_model2 %&gt;% summary ## Model Details: ## ============== ## ## H2OBinomialModel: gbm ## Model Key: GBM_model_R_1569766512944_54 ## Model Summary: ## number_of_trees number_of_internal_trees model_size_in_bytes min_depth ## 1 50 50 14179 5 ## max_depth mean_depth min_leaves max_leaves mean_leaves ## 1 5 5.00000 9 26 17.58000 ## ## H2OBinomialMetrics: gbm ## ** Reported on training data. ** ## ## MSE: 0.07258735 ## RMSE: 0.2694204 ## LogLoss: 0.2676266 ## Mean Per-Class Error: 0.07134031 ## AUC: 0.9794455 ## Gini: 0.958891 ## ## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold: ## Bad Good Error Rate ## Bad 210 25 0.106383 =25/235 ## Good 20 531 0.036298 =20/551 ## Totals 230 556 0.057252 =45/786 ## ## Maximum Metrics: Maximum metrics at their respective thresholds ## metric threshold value idx ## 1 max f1 0.585928 0.959350 231 ## 2 max f2 0.528659 0.973467 251 ## 3 max f0point5 0.641146 0.964326 215 ## 4 max accuracy 0.585928 0.942748 231 ## 5 max precision 0.985738 1.000000 0 ## 6 max recall 0.301839 1.000000 324 ## 7 max specificity 0.985738 1.000000 0 ## 8 max absolute_mcc 0.585928 0.862683 231 ## 9 max min_per_class_accuracy 0.650274 0.932849 211 ## 10 max mean_per_class_accuracy 0.641146 0.936919 215 ## ## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)` ## H2OBinomialMetrics: gbm ## ** Reported on validation data. ** ## ## MSE: 0.1745567 ## RMSE: 0.4177998 ## LogLoss: 0.5180404 ## Mean Per-Class Error: 0.4451729 ## AUC: 0.7696438 ## Gini: 0.5392876 ## ## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold: ## Bad Good Error Rate ## Bad 8 57 0.876923 =57/65 ## Good 2 147 0.013423 =2/149 ## Totals 10 204 0.275701 =59/214 ## ## Maximum Metrics: Maximum metrics at their respective thresholds ## metric threshold value idx ## 1 max f1 0.230574 0.832861 203 ## 2 max f2 0.175454 0.924318 209 ## 3 max f0point5 0.643835 0.829662 132 ## 4 max accuracy 0.579584 0.757009 148 ## 5 max precision 0.983556 1.000000 0 ## 6 max recall 0.175454 1.000000 209 ## 7 max specificity 0.983556 1.000000 0 ## 8 max absolute_mcc 0.643835 0.427333 132 ## 9 max min_per_class_accuracy 0.705292 0.707692 124 ## 10 max mean_per_class_accuracy 0.643835 0.725348 132 ## ## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)` ## ## ## Scoring History: ## timestamp duration number_of_trees training_rmse ## 1 2019-09-29 21:15:41 0.036 sec 0 0.45781 ## 2 2019-09-29 21:15:41 0.156 sec 1 0.44489 ## 3 2019-09-29 21:15:41 0.188 sec 2 0.43324 ## 4 2019-09-29 21:15:41 0.216 sec 3 0.42313 ## 5 2019-09-29 21:15:41 0.244 sec 4 0.41501 ## training_logloss training_auc training_lift ## 1 0.61000 0.50000 1.00000 ## 2 0.58254 0.82314 1.42650 ## 3 0.55877 0.83729 1.42650 ## 4 0.53861 0.85373 1.42650 ## 5 0.52240 0.86354 1.42650 ## training_classification_error validation_rmse validation_logloss ## 1 0.29898 0.45990 0.61405 ## 2 0.22774 0.45392 0.60102 ## 3 0.21374 0.45093 0.59421 ## 4 0.20738 0.44796 0.58744 ## 5 0.19338 0.44516 0.58122 ## validation_auc validation_lift validation_classification_error ## 1 0.50000 1.00000 0.30374 ## 2 0.66598 1.10480 0.30374 ## 3 0.66004 1.07718 0.29907 ## 4 0.66324 1.07718 0.28037 ## 5 0.67491 0.95749 0.26636 ## ## --- ## timestamp duration number_of_trees training_rmse ## 46 2019-09-29 21:15:43 1.700 sec 45 0.27706 ## 47 2019-09-29 21:15:43 1.732 sec 46 0.27555 ## 48 2019-09-29 21:15:43 1.764 sec 47 0.27383 ## 49 2019-09-29 21:15:43 1.800 sec 48 0.27225 ## 50 2019-09-29 21:15:43 1.836 sec 49 0.27105 ## 51 2019-09-29 21:15:43 1.924 sec 50 0.26942 ## training_logloss training_auc training_lift ## 46 0.27988 0.97668 1.42650 ## 47 0.27727 0.97715 1.42650 ## 48 0.27464 0.97787 1.42650 ## 49 0.27199 0.97879 1.42650 ## 50 0.27012 0.97924 1.42650 ## 51 0.26763 0.97945 1.42650 ## training_classification_error validation_rmse validation_logloss ## 46 0.06234 0.41681 0.51647 ## 47 0.06107 0.41697 0.51699 ## 48 0.05980 0.41727 0.51749 ## 49 0.05980 0.41718 0.51717 ## 50 0.05852 0.41795 0.51830 ## 51 0.05725 0.41780 0.51804 ## validation_auc validation_lift validation_classification_error ## 46 0.76964 1.43624 0.28037 ## 47 0.76944 1.43624 0.28037 ## 48 0.76820 1.43624 0.28037 ## 49 0.76923 1.43624 0.27570 ## 50 0.76758 1.43624 0.27570 ## 51 0.76964 1.43624 0.27570 ## ## Variable Importances: (Extract with `h2o.varimp`) ## ================================================= ## ## Variable Importances: ## variable relative_importance scaled_importance ## 1 CheckingAccountStatus.none 84.350624 1.000000 ## 2 Amount 82.419136 0.977102 ## 3 Duration 68.733696 0.814857 ## 4 Age 31.725632 0.376116 ## 5 Purpose.NewCar 19.282278 0.228597 ## percentage ## 1 0.156410 ## 2 0.152829 ## 3 0.127452 ## 4 0.058828 ## 5 0.035755 ## ## --- ## variable relative_importance scaled_importance ## 54 Housing.ForFree 0.132180 0.001567 ## 55 Purpose.DomesticAppliance 0.000000 0.000000 ## 56 Purpose.Retraining 0.000000 0.000000 ## 57 Purpose.Other 0.000000 0.000000 ## 58 Personal.Male.Divorced.Seperated 0.000000 0.000000 ## 59 Job.UnemployedUnskilled 0.000000 0.000000 ## percentage ## 54 0.000245 ## 55 0.000000 ## 56 0.000000 ## 57 0.000000 ## 58 0.000000 ## 59 0.000000 20.3.9 Tuning Tuning là quá trình tìm kiếm tổ hợp các tham số để tối ưu hóa mô hình (chất lượng dự báo tốt nhất có thể). # Bước 9: Tuning # 9.1. Set hyper parameters hyper_params = list( ## restrict the search to the range of max_depth established above max_depth = c(5:9), ## search a large space of row sampling rates per tree sample_rate = seq(0.5,1,0.05), ## search a large space of column sampling rates per split col_sample_rate = seq(0.5,1,0.05), ## search a large space of the number of min rows in a terminal node min_rows = 2^seq(0,log2(nrow(train))-1,1), ## search a large space of the number of bins for split-finding for continuous and integer columns nbins = 2^seq(4,10,1), ## search a large space of the number of bins for split-finding for categorical columns nbins_cats = 2^seq(4,12,1), ## search a few minimum required relative error improvement thresholds for a split to happen min_split_improvement = c(0,1e-8,1e-6,1e-4), ## try all histogram types (QuantilesGlobal and RoundRobin are good for numeric columns with outliers) histogram_type = c(&quot;UniformAdaptive&quot;,&quot;QuantilesGlobal&quot;,&quot;RoundRobin&quot;) ) # 9.2. Set search criteria search_criteria = list( ## Random grid search strategy = &quot;RandomDiscrete&quot;, ## limit the runtime to xx minutes max_runtime_secs = 10, ## build no more than xx models max_models = 5, ## random number generator seed to make sampling of parameter combinations reproducible seed = 1234, ## early stopping once the leaderboard of the top 5 models is converged to 0.1% relative difference stopping_rounds = 5, stopping_metric = &quot;AUC&quot;, stopping_tolerance = 1e-3 ) # 9.3. Grid search grid &lt;- h2o.grid( ## hyper parameters hyper_params = hyper_params, ## hyper-parameter search configuration (see above) search_criteria = search_criteria, ## which algorithm to run algorithm = &quot;gbm&quot;, ## identifier for the grid, to later retrieve it grid_id = &quot;model_id&quot;, ## standard model parameters x = setdiff(names(GermanCredit), &quot;Class&quot;), y = &quot;Class&quot;, training_frame = train, validation_frame = test, #balance_classes = T, #Option to solve imbalanced classification ## more trees is better if the learning rate is small enough ## use &quot;more than enough&quot; trees - we have early stopping ntrees = 200, ## smaller learning rate is better ## since we have learning_rate_annealing, we can afford to start with a bigger learning rate learn_rate = 0.05, ## learning rate annealing: learning_rate shrinks by 1% after every tree ## (use 1.00 to disable, but then lower the learning_rate) learn_rate_annealing = 0.99, ## early stopping based on timeout (no model should take more than 1 hour - modify as needed) max_runtime_secs = 30, ## early stopping once the validation AUC doesn&#39;t improve by at least 0.01% for 5 consecutive scoring events stopping_rounds = 5, stopping_tolerance = 1e-3, stopping_metric = &quot;AUC&quot;, ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval) score_tree_interval = 10, ## base random number generator seed for each model (automatically gets incremented internally for each model) seed = 1234 ) ## | | | 0% | | | 1% | |======= | 11% | |============== | 21% | |===================== | 32% | |=========================== | 42% | |================================== | 52% | |========================================= | 63% | |=============================================== | 73% | |====================================================== | 83% | |============================================================= | 94% | |=================================================================| 100% # 9.4. Get models sortedGrid &lt;- h2o.getGrid(&quot;model_id&quot;, sort_by = &quot;auc&quot;, decreasing = TRUE) sortedGrid ## H2O Grid Details ## ================ ## ## Grid ID: model_id ## Used hyper parameters: ## - col_sample_rate ## - histogram_type ## - max_depth ## - min_rows ## - min_split_improvement ## - nbins ## - nbins_cats ## - sample_rate ## Number of models: 2 ## Number of failed models: 0 ## ## Hyper-Parameter Search Summary: ordered by decreasing auc ## col_sample_rate histogram_type max_depth min_rows min_split_improvement ## 1 0.85 RoundRobin 6 1.0 1.0E-6 ## 2 0.7 RoundRobin 7 32.0 0.0 ## nbins nbins_cats sample_rate model_ids auc ## 1 128 64 0.6 model_id_model_0 0.7895715023231802 ## 2 1024 2048 0.75 model_id_model_1 0.6519876097057306 # 9.5. Get best model gbm &lt;- h2o.getModel(sortedGrid@model_ids[[1]]) # Parameters of the best model gbm@parameters ## $model_id ## [1] &quot;model_id_model_0&quot; ## ## $training_frame ## [1] &quot;RTMP_sid_a89c_2&quot; ## ## $validation_frame ## [1] &quot;RTMP_sid_a89c_4&quot; ## ## $score_tree_interval ## [1] 10 ## ## $ntrees ## [1] 200 ## ## $max_depth ## [1] 6 ## ## $min_rows ## [1] 1 ## ## $nbins ## [1] 128 ## ## $nbins_cats ## [1] 64 ## ## $stopping_rounds ## [1] 5 ## ## $stopping_metric ## [1] &quot;AUC&quot; ## ## $max_runtime_secs ## [1] 10 ## ## $seed ## [1] 1234 ## ## $learn_rate ## [1] 0.05 ## ## $learn_rate_annealing ## [1] 0.99 ## ## $distribution ## [1] &quot;bernoulli&quot; ## ## $sample_rate ## [1] 0.6 ## ## $col_sample_rate ## [1] 0.85 ## ## $min_split_improvement ## [1] 1e-06 ## ## $histogram_type ## [1] &quot;RoundRobin&quot; ## ## $x ## [1] &quot;Duration&quot; ## [2] &quot;Amount&quot; ## [3] &quot;InstallmentRatePercentage&quot; ## [4] &quot;ResidenceDuration&quot; ## [5] &quot;Age&quot; ## [6] &quot;NumberExistingCredits&quot; ## [7] &quot;NumberPeopleMaintenance&quot; ## [8] &quot;Telephone&quot; ## [9] &quot;ForeignWorker&quot; ## [10] &quot;CheckingAccountStatus.lt.0&quot; ## [11] &quot;CheckingAccountStatus.0.to.200&quot; ## [12] &quot;CheckingAccountStatus.gt.200&quot; ## [13] &quot;CheckingAccountStatus.none&quot; ## [14] &quot;CreditHistory.NoCredit.AllPaid&quot; ## [15] &quot;CreditHistory.ThisBank.AllPaid&quot; ## [16] &quot;CreditHistory.PaidDuly&quot; ## [17] &quot;CreditHistory.Delay&quot; ## [18] &quot;CreditHistory.Critical&quot; ## [19] &quot;Purpose.NewCar&quot; ## [20] &quot;Purpose.UsedCar&quot; ## [21] &quot;Purpose.Furniture.Equipment&quot; ## [22] &quot;Purpose.Radio.Television&quot; ## [23] &quot;Purpose.DomesticAppliance&quot; ## [24] &quot;Purpose.Repairs&quot; ## [25] &quot;Purpose.Education&quot; ## [26] &quot;Purpose.Retraining&quot; ## [27] &quot;Purpose.Business&quot; ## [28] &quot;Purpose.Other&quot; ## [29] &quot;SavingsAccountBonds.lt.100&quot; ## [30] &quot;SavingsAccountBonds.100.to.500&quot; ## [31] &quot;SavingsAccountBonds.500.to.1000&quot; ## [32] &quot;SavingsAccountBonds.gt.1000&quot; ## [33] &quot;SavingsAccountBonds.Unknown&quot; ## [34] &quot;EmploymentDuration.lt.1&quot; ## [35] &quot;EmploymentDuration.1.to.4&quot; ## [36] &quot;EmploymentDuration.4.to.7&quot; ## [37] &quot;EmploymentDuration.gt.7&quot; ## [38] &quot;EmploymentDuration.Unemployed&quot; ## [39] &quot;Personal.Male.Divorced.Seperated&quot; ## [40] &quot;Personal.Female.NotSingle&quot; ## [41] &quot;Personal.Male.Single&quot; ## [42] &quot;Personal.Male.Married.Widowed&quot; ## [43] &quot;OtherDebtorsGuarantors.None&quot; ## [44] &quot;OtherDebtorsGuarantors.CoApplicant&quot; ## [45] &quot;OtherDebtorsGuarantors.Guarantor&quot; ## [46] &quot;Property.RealEstate&quot; ## [47] &quot;Property.Insurance&quot; ## [48] &quot;Property.CarOther&quot; ## [49] &quot;Property.Unknown&quot; ## [50] &quot;OtherInstallmentPlans.Bank&quot; ## [51] &quot;OtherInstallmentPlans.Stores&quot; ## [52] &quot;OtherInstallmentPlans.None&quot; ## [53] &quot;Housing.Rent&quot; ## [54] &quot;Housing.Own&quot; ## [55] &quot;Housing.ForFree&quot; ## [56] &quot;Job.UnemployedUnskilled&quot; ## [57] &quot;Job.UnskilledResident&quot; ## [58] &quot;Job.SkilledEmployee&quot; ## [59] &quot;Job.Management.SelfEmp.HighlyQualified&quot; ## ## $y ## [1] &quot;Class&quot; # Summary best model gbm %&gt;% summary ## Model Details: ## ============== ## ## H2OBinomialModel: gbm ## Model Key: model_id_model_0 ## Model Summary: ## number_of_trees number_of_internal_trees model_size_in_bytes min_depth ## 1 150 150 87566 6 ## max_depth mean_depth min_leaves max_leaves mean_leaves ## 1 6 6.00000 25 56 41.36666 ## ## H2OBinomialMetrics: gbm ## ** Reported on training data. ** ## ## MSE: 0.04609157 ## RMSE: 0.2146895 ## LogLoss: 0.1975817 ## Mean Per-Class Error: 0.03279144 ## AUC: 0.9968413 ## Gini: 0.9936827 ## ## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold: ## Bad Good Error Rate ## Bad 223 12 0.051064 =12/235 ## Good 8 543 0.014519 =8/551 ## Totals 231 555 0.025445 =20/786 ## ## Maximum Metrics: Maximum metrics at their respective thresholds ## metric threshold value idx ## 1 max f1 0.557658 0.981917 233 ## 2 max f2 0.494161 0.989189 246 ## 3 max f0point5 0.683415 0.985837 215 ## 4 max accuracy 0.606647 0.974555 224 ## 5 max precision 0.981744 1.000000 0 ## 6 max recall 0.416175 1.000000 265 ## 7 max specificity 0.981744 1.000000 0 ## 8 max absolute_mcc 0.606647 0.939893 224 ## 9 max min_per_class_accuracy 0.635032 0.970213 222 ## 10 max mean_per_class_accuracy 0.606647 0.973310 224 ## ## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)` ## H2OBinomialMetrics: gbm ## ** Reported on validation data. ** ## ## MSE: 0.1640402 ## RMSE: 0.4050187 ## LogLoss: 0.49375 ## Mean Per-Class Error: 0.3412494 ## AUC: 0.7895715 ## Gini: 0.579143 ## ## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold: ## Bad Good Error Rate ## Bad 25 40 0.615385 =40/65 ## Good 10 139 0.067114 =10/149 ## Totals 35 179 0.233645 =50/214 ## ## Maximum Metrics: Maximum metrics at their respective thresholds ## metric threshold value idx ## 1 max f1 0.419420 0.847561 178 ## 2 max f2 0.240139 0.928928 205 ## 3 max f0point5 0.566980 0.832250 154 ## 4 max accuracy 0.566980 0.775701 154 ## 5 max precision 0.979432 1.000000 0 ## 6 max recall 0.240139 1.000000 205 ## 7 max specificity 0.979432 1.000000 0 ## 8 max absolute_mcc 0.566980 0.456587 154 ## 9 max min_per_class_accuracy 0.733737 0.707692 124 ## 10 max mean_per_class_accuracy 0.566980 0.721838 154 ## ## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)` ## ## ## Scoring History: ## timestamp duration number_of_trees training_rmse ## 1 2019-09-29 21:15:44 0.039 sec 0 0.45781 ## 2 2019-09-29 21:15:47 2.234 sec 10 0.38763 ## 3 2019-09-29 21:15:47 2.462 sec 20 0.34544 ## 4 2019-09-29 21:15:47 2.730 sec 30 0.31670 ## 5 2019-09-29 21:15:47 2.962 sec 40 0.29576 ## 6 2019-09-29 21:15:47 3.186 sec 50 0.28082 ## 7 2019-09-29 21:15:48 3.370 sec 60 0.26738 ## 8 2019-09-29 21:15:48 3.534 sec 70 0.25817 ## 9 2019-09-29 21:15:48 3.690 sec 80 0.24905 ## 10 2019-09-29 21:15:48 3.858 sec 90 0.24140 ## 11 2019-09-29 21:15:48 4.026 sec 100 0.23425 ## 12 2019-09-29 21:15:48 4.222 sec 110 0.22978 ## 13 2019-09-29 21:15:49 4.402 sec 120 0.22572 ## 14 2019-09-29 21:15:49 4.598 sec 130 0.22135 ## 15 2019-09-29 21:15:49 4.782 sec 140 0.21774 ## 16 2019-09-29 21:15:49 4.969 sec 150 0.21469 ## training_logloss training_auc training_lift ## 1 0.61000 0.50000 1.00000 ## 2 0.47229 0.95625 1.42650 ## 3 0.39750 0.96806 1.42650 ## 4 0.34908 0.97642 1.42650 ## 5 0.31446 0.98191 1.42650 ## 6 0.29155 0.98548 1.42650 ## 7 0.27135 0.98910 1.42650 ## 8 0.25757 0.99003 1.42650 ## 9 0.24450 0.99217 1.42650 ## 10 0.23374 0.99351 1.42650 ## 11 0.22409 0.99471 1.42650 ## 12 0.21782 0.99510 1.42650 ## 13 0.21203 0.99559 1.42650 ## 14 0.20626 0.99609 1.42650 ## 15 0.20152 0.99660 1.42650 ## 16 0.19758 0.99684 1.42650 ## training_classification_error validation_rmse validation_logloss ## 1 0.29898 0.45990 0.61405 ## 2 0.08015 0.43239 0.55531 ## 3 0.07761 0.41915 0.52568 ## 4 0.06234 0.41203 0.51035 ## 5 0.05852 0.40949 0.50433 ## 6 0.04835 0.40745 0.50014 ## 7 0.03690 0.40660 0.49789 ## 8 0.03690 0.40707 0.49831 ## 9 0.03562 0.40673 0.49703 ## 10 0.03181 0.40501 0.49333 ## 11 0.02799 0.40554 0.49441 ## 12 0.02799 0.40566 0.49456 ## 13 0.02799 0.40601 0.49527 ## 14 0.02672 0.40565 0.49485 ## 15 0.02545 0.40512 0.49357 ## 16 0.02545 0.40502 0.49375 ## validation_auc validation_lift validation_classification_error ## 1 0.50000 1.00000 0.30374 ## 2 0.75333 1.43624 0.26168 ## 3 0.77357 1.43624 0.26636 ## 4 0.78503 1.43624 0.21495 ## 5 0.78482 1.43624 0.21495 ## 6 0.78699 1.43624 0.21495 ## 7 0.78771 1.43624 0.21963 ## 8 0.78616 1.43624 0.22897 ## 9 0.78730 1.43624 0.21963 ## 10 0.78998 1.43624 0.22897 ## 11 0.78926 1.43624 0.23832 ## 12 0.78875 1.43624 0.23832 ## 13 0.78792 1.43624 0.23832 ## 14 0.78813 1.43624 0.23832 ## 15 0.78906 1.43624 0.23364 ## 16 0.78957 1.43624 0.23364 ## ## Variable Importances: (Extract with `h2o.varimp`) ## ================================================= ## ## Variable Importances: ## variable relative_importance scaled_importance ## 1 Amount 271.652588 1.000000 ## 2 CheckingAccountStatus.none 183.992157 0.677307 ## 3 Duration 174.874634 0.643744 ## 4 Age 168.345612 0.619709 ## 5 InstallmentRatePercentage 56.974583 0.209733 ## percentage ## 1 0.149237 ## 2 0.101079 ## 3 0.096070 ## 4 0.092484 ## 5 0.031300 ## ## --- ## variable relative_importance scaled_importance ## 54 Purpose.Repairs 7.493972 0.027587 ## 55 ForeignWorker 6.335423 0.023322 ## 56 Job.UnemployedUnskilled 4.599856 0.016933 ## 57 Purpose.Retraining 3.144078 0.011574 ## 58 Purpose.DomesticAppliance 1.838258 0.006767 ## 59 Purpose.Other 0.832699 0.003065 ## percentage ## 54 0.004117 ## 55 0.003480 ## 56 0.002527 ## 57 0.001727 ## 58 0.001010 ## 59 0.000457 20.3.10 Lưu và load mô hình Để lưu lại mô hình trên H2O, chúng ta sử dụng câu lệnh h2o.saveModel(). # Lưu model h2o.saveModel(gbm, # Tên mô hình path = getwd(), # Đường dẫn muốn lưu force = T) Để load mô hình trên H2O, chúng ta sử dụng câu lệnh h2o.loadModel(). Như vậy, trong chương này, chúng ta được học cách xây dựng mô hình dự báo với H2O. Đây là một platform rất mạnh giúp cải thiện chất lượng dự báo, tốc độ xử lý, tối ưu hóa mô hình, cũng như hiển thị kết quả mô hình một cách rất hiệu quả. 20.4 Tài liệu tham khảo https://github.com/h2oai/h2o-tutorials "]
]
